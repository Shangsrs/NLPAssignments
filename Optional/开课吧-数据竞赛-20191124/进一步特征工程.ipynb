{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "pd.set_option('display.max_columns', None)\n",
    "#encoding=utf8\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "#from com_util import *\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../input/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../input/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../input/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../input/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_onehot(df,column_name):\n",
    "    feature_df=pd.get_dummies(df[column_name], prefix=column_name)\n",
    "    all = pd.concat([df.drop([column_name], axis=1),feature_df], axis=1)\n",
    "    return all\n",
    "\n",
    "def encode_count(df,column_name):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(df[column_name].values))\n",
    "    df[column_name] = lbl.transform(list(df[column_name].values))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['as']=encode_count(data['as'],\"air_genre_name\")\n",
    "data['as']=encode_count(data['as'],\"air_area_name\")\n",
    "\n",
    "data['hs']=encode_count(data['hs'],\"hpg_genre_name\")\n",
    "data['hs']=encode_count(data['hs'],\"hpg_area_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hol'].columns=[\"visit_date\",\"day_of_week\",\"holiday_flg\"]\n",
    "data['hol'][\"day_of_week\"]=data['hol'][\"day_of_week\"].replace({\"Monday\":1,\"Tuesday\":2,\"Wednesday\":3,\"Thursday\":4,\"Friday\":5,\"Saturday\":6,\"Sunday\":7})\n",
    "data['hol'][\"holiday\"] = ((data['hol'][\"day_of_week\"]>=6) | (data['hol'][\"holiday_flg\"]==1)).astype(int)\n",
    "#df_date_info[\"holiday\"]= map(lambda a, b: 1 if a in [6, 7] or b == 1 else 0, df_date_info[\"day_of_week\"], df_date_info[\"holiday_flg\"])\n",
    "del data['hol'][\"day_of_week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tra'][\"visitors\"]=data['tra'][\"visitors\"].apply(lambda x: np.log1p(float(x)) if float(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name  air_area_name   latitude   longitude\n",
       "0  air_0f0cdeee6c9bf3d7               6             27  34.695124  135.197852\n",
       "1  air_7cc17a324ae5c7dc               6             27  34.695124  135.197852\n",
       "2  air_fee8dcf4d619598e               6             27  34.695124  135.197852\n",
       "3  air_a17f0778617c76e2               6             27  34.695124  135.197852\n",
       "4  air_83db5aff8f50478e               6             62  35.658068  139.751599"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['as'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hr']= pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "data['ar'][\"reserve_date\"]=data['ar'][\"reserve_datetime\"].apply(lambda x:x.split(\" \")[0])\n",
    "data['ar'][\"visit_date\"]=data['ar'][\"visit_datetime\"].apply(lambda x:x.split(\" \")[0])\n",
    "\n",
    "data['hr'][\"reserve_date\"]=data['hr'][\"reserve_datetime\"].apply(lambda x:x.split(\" \")[0])\n",
    "data['hr'][\"visit_date\"]=data['hr'][\"visit_datetime\"].apply(lambda x:x.split(\" \")[0])\n",
    "data['ar']['reserve_datetime_diff'] = (pd.to_datetime(data['ar']['visit_date']) - pd.to_datetime(data['ar']['reserve_date'])).dt.days\n",
    "data['hr']['reserve_datetime_diff'] = (pd.to_datetime(data['hr']['visit_date']) - pd.to_datetime(data['hr']['reserve_date'])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['tes']\n",
    "\n",
    "data['tes'][\"air_store_id\"]=data['tes'][\"id\"].apply(lambda x:\"_\".join(x.split(\"_\")[:2]))\n",
    "data['tes'][\"visit_date\"]=data['tes'][\"id\"].apply(lambda x:x.split(\"_\")[2])\n",
    "del data['tes'][\"visitors\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tra'] = data['tra'].merge(data['id'],on=[\"air_store_id\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors reserve_date  visit_date  reserve_datetime_diff  \n",
       "0                 1   2016-01-01  2016-01-01                      0  \n",
       "1                 3   2016-01-01  2016-01-01                      0  \n",
       "2                 6   2016-01-01  2016-01-01                      0  \n",
       "3                 2   2016-01-01  2016-01-01                      0  \n",
       "4                 5   2016-01-01  2016-01-01                      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ar'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.258097\n",
       "1    3.496508\n",
       "2    3.401197\n",
       "3    3.135494\n",
       "4    1.945910\n",
       "Name: visitors, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tra'][\"visitors\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_878cc70b1abc76f7</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 15:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_878cc70b1abc76f7</td>\n",
       "      <td>2016-01-02 19:00:00</td>\n",
       "      <td>2016-01-02 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_878cc70b1abc76f7</td>\n",
       "      <td>2016-01-03 18:00:00</td>\n",
       "      <td>2016-01-02 20:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_878cc70b1abc76f7</td>\n",
       "      <td>2016-01-06 20:00:00</td>\n",
       "      <td>2016-01-04 22:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_878cc70b1abc76f7</td>\n",
       "      <td>2016-01-11 18:00:00</td>\n",
       "      <td>2016-01-11 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  hpg_878cc70b1abc76f7  2016-01-01 19:00:00  2016-01-01 15:00:00   \n",
       "1  hpg_878cc70b1abc76f7  2016-01-02 19:00:00  2016-01-02 14:00:00   \n",
       "2  hpg_878cc70b1abc76f7  2016-01-03 18:00:00  2016-01-02 20:00:00   \n",
       "3  hpg_878cc70b1abc76f7  2016-01-06 20:00:00  2016-01-04 22:00:00   \n",
       "4  hpg_878cc70b1abc76f7  2016-01-11 18:00:00  2016-01-11 14:00:00   \n",
       "\n",
       "   reserve_visitors          air_store_id reserve_date  visit_date  \\\n",
       "0                 4  air_db80363d35f10926   2016-01-01  2016-01-01   \n",
       "1                 2  air_db80363d35f10926   2016-01-02  2016-01-02   \n",
       "2                 6  air_db80363d35f10926   2016-01-02  2016-01-03   \n",
       "3                 3  air_db80363d35f10926   2016-01-04  2016-01-06   \n",
       "4                 2  air_db80363d35f10926   2016-01-11  2016-01-11   \n",
       "\n",
       "   reserve_datetime_diff  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hr'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  特征架子\n",
    "def feat_sum(df, df_feature, fe,value,name=\"\"):\n",
    "    #当我们 一个值去匹配另一组个数不一致的时候进行统计特征的时候，往往会使用groupby 。数学公式\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].sum()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_sum\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def feat_mean(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].mean()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_mean\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_count(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].count()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_count\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_onehot(df,column_name):\n",
    "    feature_df=pd.get_dummies(df[column_name], prefix=column_name)\n",
    "    all = pd.concat([df.drop([column_name], axis=1),feature_df], axis=1)\n",
    "    return all\n",
    "\n",
    "def encode_count(df,column_name):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(df[column_name].values))\n",
    "    df[column_name] = lbl.transform(list(df[column_name].values))\n",
    "    return df\n",
    "\n",
    "def merge_count(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].count()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_nunique(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].nunique()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_median(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].median()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_mean(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].mean()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_sum(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].sum()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_max(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].max()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_min(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].min()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def merge_std(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].std()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "# df['sda']=df.groupby(columns)[value].transform('std')\n",
    "\n",
    "# df['aggmean']=df.groupby(columns)[value].transform('mean')\n",
    "\n",
    "def merge_var(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].var()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def feat_count(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].count()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_count\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_nunique(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].nunique()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_nunique\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_mean(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].mean()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_mean\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_kernelMedian(df, df_feature, fe, value, pr, name=\"\"):\n",
    "    def get_median(a, pr=pr):\n",
    "        a = np.array(a)\n",
    "        x = a[~np.isnan(a)]\n",
    "        n = len(x)\n",
    "        weight = np.repeat(1.0, n)\n",
    "        idx = np.argsort(x)\n",
    "        x = x[idx]\n",
    "        if n<pr.shape[0]:\n",
    "            pr = pr[n,:n]\n",
    "        else:\n",
    "            scale = (n-1)/2.\n",
    "            xxx = np.arange(-(n+1)/2.+1, (n+1)/2., step=1)/scale\n",
    "            yyy = 3./4.*(1-xxx**2)\n",
    "            yyy = yyy/np.sum(yyy)\n",
    "            pr = (yyy*n+1)/(n+1)\n",
    "        ans = np.sum(pr*x*weight) / float(np.sum(pr * weight))\n",
    "        return ans\n",
    "\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].apply(get_median)).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_mean\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_std(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].std()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_std\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_median(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].median()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_median\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_max(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].max()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_max\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_min(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].min()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_min\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_sum(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].sum()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_sum\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_var(df, df_feature, fe,value,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].var()).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_var\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "\n",
    "def feat_quantile(df, df_feature, fe,value,n,name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].quantile(n)).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_quantile\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_gap(x,y):\n",
    "    a,b,c=x.split(\"-\")\n",
    "    return (date(int(a),int(b),int(c))-y).days\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def date_handle(df):\n",
    "    df_visit_date=pd.to_datetime(df[\"visit_date\"])\n",
    "    df[\"weekday\"]=df_visit_date.dt.weekday\n",
    "    df[\"day\"]=df_visit_date.dt.day\n",
    "    days_of_months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    #  2. 新的特征 \"days_to_side\" 表示当天距离月初月末的最短距离\n",
    "    df[\"days_to_side\"] = df_visit_date.apply(\n",
    "        lambda x: min(x.day, days_of_months[x.month-1]-x.day))\n",
    "    # Feiyang: 3. 把月初月末的定义改成了7天\n",
    "    df[\"day\"]=df[\"day\"].apply(lambda x:0 if x<=7 else 2 if x>=24 else 1)\n",
    "    df = df.merge(data['as'], on=\"air_store_id\", how=\"left\").fillna(-1)\n",
    "    #df = df.merge(hpg_info, on=\"hpg_store_id\", how=\"left\").fillna(-1)\n",
    "    df = df.merge(data['hol'], on=\"visit_date\", how=\"left\").fillna(-1)\n",
    "    #df[\"holiday\"] = map(lambda a, b: 1 if a in [5, 6] or b == 1 else 0, df[\"weekday\"], df[\"holiday_flg\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df_label,df_train,df_air_reserve,df_hpg_reserve):\n",
    "    df_train=date_handle(df_train)\n",
    "    df_label=date_handle(df_label)\n",
    "    df_label=feat_sum(df_label,df_air_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_datetime_diff\",\"air_reserve_datetime_diff_sum\")\n",
    "    df_label=feat_sum(df_label,df_air_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"air_reserve_visitors_sum\")\n",
    "    df_label=feat_sum(df_label,df_air_reserve,[\"visit_date\"],\"reserve_visitors\",\"air_date_reserve_visitors_sum\")\n",
    "    df_label=feat_sum(df_label,df_hpg_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_datetime_diff\",\"hpg_reserve_datetime_diff_sum\")\n",
    "    df_label=feat_sum(df_label,df_hpg_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"hpg_reserve_visitors_sum\")\n",
    "    df_label=feat_sum(df_label,df_hpg_reserve,[\"visit_date\"],\"reserve_visitors\",\"hpg_date_reserve_visitors_sum\")\n",
    "    \n",
    "    df_label=feat_mean(df_label,df_air_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_datetime_diff\",\"air_reserve_datetime_diff_mean\")\n",
    "    df_label=feat_mean(df_label,df_air_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"air_reserve_visitors_mean\")\n",
    "    df_label=feat_mean(df_label,df_air_reserve,[\"visit_date\"],\"reserve_visitors\",\"air_date_reserve_visitors_mean\")\n",
    "    df_label=feat_mean(df_label,df_hpg_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_datetime_diff\",\"hpg_reserve_datetime_diff_mean\")\n",
    "    df_label=feat_mean(df_label,df_hpg_reserve,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"hpg_reserve_visitors_mean\")\n",
    "    df_label=feat_mean(df_label,df_hpg_reserve,[\"visit_date\"],\"reserve_visitors\",\"hpg_date_reserve_visitors_mean\")\n",
    "    \n",
    "    \n",
    "    for i in [7,14,35,63,140]:\n",
    "        df_air_reserve_select=df_air_reserve[df_air_reserve.day_gap>=-i].copy()\n",
    "        df_hpg_reserve_select=df_hpg_reserve[df_hpg_reserve.day_gap>=-i].copy()\n",
    "        \n",
    "        date_air_reserve=pd.DataFrame(df_air_reserve_select.groupby([\"air_store_id\",\"visit_date\"]).reserve_visitors.sum()).reset_index()\n",
    "        date_air_reserve.columns=[\"air_store_id\",\"visit_date\",\"reserve_visitors_sum\"]\n",
    "        date_air_reserve=feat_count(date_air_reserve,df_air_reserve_select,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"reserve_visitors_count\")\n",
    "        date_air_reserve=feat_mean(date_air_reserve,df_air_reserve_select,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"reserve_visitors_mean\")\n",
    "\n",
    "        date_hpg_reserve=pd.DataFrame(df_hpg_reserve_select.groupby([\"air_store_id\",\"visit_date\"]).reserve_visitors.sum()).reset_index()\n",
    "        date_hpg_reserve.columns=[\"air_store_id\",\"visit_date\",\"reserve_visitors_sum\"]\n",
    "        date_hpg_reserve=feat_count(date_hpg_reserve,df_hpg_reserve_select,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"reserve_visitors_count\")\n",
    "        date_hpg_reserve=feat_mean(date_hpg_reserve,df_hpg_reserve_select,[\"air_store_id\",\"visit_date\"],\"reserve_visitors\",\"reserve_visitors_mean\")\n",
    "        \n",
    "        \n",
    "        date_air_reserve=date_handle(date_air_reserve)\n",
    "        date_hpg_reserve=date_handle(date_hpg_reserve)\n",
    "        date_air_reserve[\"holiday\"] = ((date_air_reserve[\"weekday\"]>=5) | (date_air_reserve[\"holiday_flg\"]==1)).astype(int)\n",
    "        date_hpg_reserve[\"holiday\"] = ((date_hpg_reserve[\"weekday\"]>=5) | (date_hpg_reserve[\"holiday_flg\"]==1)).astype(int)\n",
    "        \n",
    "        df_label=feat_mean(df_label,date_air_reserve,[\"air_store_id\",\"weekday\"],\"reserve_visitors_sum\", \"air_reserve_visitors_sum_weekday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_hpg_reserve,[\"air_store_id\",\"weekday\"],\"reserve_visitors_sum\", \"hpg_reserve_visitors_sum_weekday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_air_reserve,[\"air_store_id\",\"weekday\"],\"reserve_visitors_mean\", \"air_reserve_visitors_mean_weekday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_hpg_reserve,[\"air_store_id\",\"weekday\"],\"reserve_visitors_mean\", \"hpg_reserve_visitors_mean_weekday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_air_reserve,[\"air_store_id\",\"weekday\"],\"reserve_visitors_count\", \"air_reserve_visitors_count_weekday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_hpg_reserve,[\"air_store_id\",\"weekday\"],\"reserve_visitors_count\", \"hpg_reserve_visitors_count_weekday_mean_%s\"%i)\n",
    "\n",
    "        df_label=feat_mean(df_label,date_air_reserve,[\"air_store_id\",\"holiday\"],\"reserve_visitors_sum\", \"air_reserve_visitors_sum_holiday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_hpg_reserve,[\"air_store_id\",\"holiday\"],\"reserve_visitors_sum\", \"hpg_reserve_visitors_sum_holiday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_air_reserve,[\"air_store_id\",\"holiday\"],\"reserve_visitors_mean\", \"air_reserve_visitors_mean_holiday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_hpg_reserve,[\"air_store_id\",\"holiday\"],\"reserve_visitors_mean\", \"hpg_reserve_visitors_mean_holiday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_air_reserve,[\"air_store_id\",\"holiday\"],\"reserve_visitors_count\", \"air_reserve_visitors_count_holiday_mean_%s\"%i)\n",
    "        df_label=feat_mean(df_label,date_hpg_reserve,[\"air_store_id\",\"holiday\"],\"reserve_visitors_count\", \"hpg_reserve_visitors_count_holiday_mean_%s\"%i)\n",
    "\n",
    "    df_label = feat_mean(df_label, df_train, [\"air_store_id\",\"day\",\"weekday\"], \"visitors\", \"air_day_mean\")\n",
    "    df_label = feat_mean(df_label, df_train, [\"air_store_id\",\"day\",\"holiday\"], \"visitors\", \"air_holiday_mean\")\n",
    "    for i in [21,35,63,140,280,350,420]:\n",
    "        df_select=df_train[df_train.day_gap>=-i].copy()\n",
    "        df_label=feat_median(df_label, df_select, [\"air_store_id\"], \"visitors\", \"air_median_%s\"%i)\n",
    "        df_label=feat_mean(df_label,df_select,[\"air_store_id\"],\"visitors\", \"air_mean_%s\"%i)\n",
    "        \n",
    "        df_label=feat_max(df_label,df_select,[\"air_store_id\"],\"visitors\",\"air_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_store_id\"],\"visitors\",\"air_min_%s\"%i)\n",
    "        df_label=feat_std(df_label,df_select,[\"air_store_id\"],\"visitors\",\"air_std_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_store_id\"],\"visitors\",\"air_count_%s\"%i)\n",
    "\n",
    "        \n",
    "        df_label=feat_mean(df_label,df_select,[\"air_store_id\",\"weekday\"],\"visitors\", \"air_week_mean_%s\"%i)\n",
    "        df_label=feat_max(df_label,df_select,[\"air_store_id\",\"weekday\"],\"visitors\",\"air_week_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_store_id\",\"weekday\"],\"visitors\",\"air_week_min_%s\"%i)\n",
    "        df_label=feat_std(df_label,df_select,[\"air_store_id\",\"weekday\"],\"visitors\",\"air_week_std_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_store_id\",\"weekday\"],\"visitors\",\"air_week_count_%s\"%i)\n",
    "\n",
    "        df_label=feat_mean(df_label,df_select,[\"air_store_id\",\"holiday\"],\"visitors\", \"air_holiday_mean_%s\"%i)\n",
    "        df_label=feat_max(df_label,df_select,[\"air_store_id\",\"holiday\"],\"visitors\",\"air_holiday_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_store_id\",\"holiday\"],\"visitors\",\"air_holiday_min_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_store_id\",\"holiday\"],\"visitors\",\"air_holiday_count_%s\"%i)\n",
    "\n",
    "        df_label=feat_mean(df_label,df_select,[\"air_genre_name\",\"holiday\"],\"visitors\", \"air_genre_name_holiday_mean_%s\"%i)\n",
    "        df_label=feat_max(df_label,df_select,[\"air_genre_name\",\"holiday\"],\"visitors\",\"air_genre_name_holiday_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_genre_name\",\"holiday\"],\"visitors\",\"air_genre_name_holiday_min_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_genre_name\",\"holiday\"],\"visitors\",\"air_genre_name_holiday_count_%s\"%i)\n",
    "\n",
    "        df_label=feat_mean(df_label,df_select,[\"air_genre_name\",\"weekday\"],\"visitors\", \"air_genre_name_weekday_mean_%s\"%i)\n",
    "        df_label=feat_max(df_label,df_select,[\"air_genre_name\",\"weekday\"],\"visitors\",\"air_genre_name_weekday_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_genre_name\",\"weekday\"],\"visitors\",\"air_genre_name_weekday_min_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_genre_name\",\"weekday\"],\"visitors\",\"air_genre_name_weekday_count_%s\"%i)\n",
    "\n",
    "        df_label=feat_mean(df_label,df_select,[\"air_area_name\",\"holiday\"],\"visitors\", \"air_area_name_holiday_mean_%s\"%i)\n",
    "        df_label=feat_max(df_label,df_select,[\"air_area_name\",\"holiday\"],\"visitors\",\"air_area_name_holiday_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_area_name\",\"holiday\"],\"visitors\",\"air_area_name_holiday_min_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_area_name\",\"holiday\"],\"visitors\",\"air_area_name_holiday_count_%s\"%i)\n",
    "\n",
    "        df_label=feat_mean(df_label,df_select,[\"air_area_name\",\"air_genre_name\",\"holiday\"],\"visitors\", \"air_area_genre_name_holiday_mean_%s\"%i)\n",
    "        df_label=feat_max(df_label,df_select,[\"air_area_name\",\"air_genre_name\",\"holiday\"],\"visitors\",\"air_area_genre_name_holiday_max_%s\"%i)\n",
    "        df_label=feat_min(df_label,df_select,[\"air_area_name\",\"air_genre_name\",\"holiday\"],\"visitors\",\"air_area_genre_name_holiday_min_%s\"%i)\n",
    "        df_label=feat_count(df_label,df_select,[\"air_area_name\",\"air_genre_name\",\"holiday\"],\"visitors\",\"air_area_genre_name_holiday_count_%s\"%i)\n",
    "    return df_label\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-09\n",
      "2017-03-26\n",
      "2017-03-12\n",
      "2017-02-26\n",
      "2017-02-12\n",
      "2017-01-29\n",
      "2017-01-15\n",
      "2017-01-01\n",
      "2016-12-18\n",
      "2016-12-04\n",
      "2016-11-20\n",
      "2016-11-06\n",
      "2016-10-23\n",
      "2016-10-09\n",
      "2016-09-25\n",
      "2016-09-11\n",
      "2016-08-28\n",
      "2016-08-14\n",
      "2016-07-31\n",
      "2016-07-17\n",
      "2016-07-03\n",
      "2016-06-19\n",
      "2016-06-05\n",
      "2016-05-22\n",
      "2016-05-08\n",
      "2016-04-24\n",
      "2016-04-10\n",
      "2016-03-27\n",
      "2016-03-13\n",
      "2016-02-28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-11ab0fc4cd4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdf_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tra'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tra'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday_gap\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tra'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday_gap\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mnday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"air_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"hpg_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"visit_date\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"day_gap\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"visitors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtrain_data_tmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_air_reserve\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_hpg_reserve\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-397be0da2c0e>\u001b[0m in \u001b[0;36mcreate_features\u001b[1;34m(df_label, df_train, df_air_reserve, df_hpg_reserve)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mdf_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeat_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_select\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"air_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"weekday\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"visitors\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"air_week_count_%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mdf_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeat_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_select\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"air_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"holiday\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"visitors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"air_holiday_mean_%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mdf_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeat_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_select\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"air_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"holiday\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"visitors\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"air_holiday_max_%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mdf_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeat_min\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_select\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"air_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"holiday\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"visitors\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"air_holiday_min_%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-110d2fee50a3>\u001b[0m in \u001b[0;36mfeat_mean\u001b[1;34m(df, df_feature, fe, value, name)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mdf_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfe\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"left\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   6387\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6388\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6389\u001b[1;33m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[0;32m   6390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                          validate=validate)\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   5419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5420\u001b[0m             b = make_block(\n\u001b[1;32m-> 5421\u001b[1;33m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5422\u001b[0m                 placement=placement)\n\u001b[0;32m   5423\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   5563\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[0;32m   5564\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[1;32m-> 5565\u001b[1;33m                  for ju in join_units]\n\u001b[0m\u001b[0;32m   5566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5567\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   5563\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[0;32m   5564\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[1;32m-> 5565\u001b[1;33m                  for ju in join_units]\n\u001b[0m\u001b[0;32m   5566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5567\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m   5873\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5874\u001b[0m                 values = algos.take_nd(values, indexer, axis=ax,\n\u001b[1;32m-> 5875\u001b[1;33m                                        fill_value=fill_value)\n\u001b[0m\u001b[0;32m   5876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5877\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for slip in [14]:   #you can add 21 35... #,28,42\n",
    "    t2017 = date(2017, 4, 23)\n",
    "    nday=slip\n",
    "\n",
    "    #构造训练集\n",
    "    all_data=[]\n",
    "    for i in range(nday*1,nday*(420//nday+1),nday):  #windowsize==step\n",
    "        delta = timedelta(days=i)\n",
    "        t_begin=t2017 - delta\n",
    "        print(t_begin)\n",
    "        data['tra'][\"day_gap\"]=data['tra'][\"visit_date\"].apply(lambda x:date_gap(x,t_begin))\n",
    "        data['ar'][\"day_gap\"]=data['ar'][\"reserve_date\"].apply(lambda x:date_gap(x,t_begin))\n",
    "        data['hr'][\"day_gap\"]=data['hr'][\"reserve_date\"].apply(lambda x:date_gap(x,t_begin))\n",
    "        \n",
    "        df_feature=data['tra'][data['tra'].day_gap<0].copy()\n",
    "        df_air_reserve=data['ar'][data['ar'].day_gap<0].copy()\n",
    "        df_hpg_reserve=data['hr'][data['hr'].day_gap<0].copy()\n",
    "        \n",
    "        df_label=data['tra'][(data['tra'].day_gap>=0)&(data['tra'].day_gap<nday)][[\"air_store_id\",\"hpg_store_id\",\"visit_date\",\"day_gap\",\"visitors\"]].copy()\n",
    "        train_data_tmp=create_features(df_label,df_feature,df_air_reserve,df_hpg_reserve)\n",
    "        all_data.append(train_data_tmp)\n",
    "\n",
    "    train=pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>day_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>-452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>-451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>-450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>-449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>-447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  day_gap\n",
       "0  air_ba937bf13d40fb24  2016-01-13  3.258097     -452\n",
       "1  air_ba937bf13d40fb24  2016-01-14  3.496508     -451\n",
       "2  air_ba937bf13d40fb24  2016-01-15  3.401197     -450\n",
       "3  air_ba937bf13d40fb24  2016-01-16  3.135494     -449\n",
       "4  air_ba937bf13d40fb24  2016-01-18  1.945910     -447"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tra'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 6  \n",
       "3                 2  \n",
       "4                 5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ar'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "      <th>day_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors reserve_date  visit_date  reserve_datetime_diff  day_gap  \n",
       "0                 1   2016-01-01  2016-01-01                      0     -464  \n",
       "1                 3   2016-01-01  2016-01-01                      0     -464  \n",
       "2                 6   2016-01-01  2016-01-01                      0     -464  \n",
       "3                 2   2016-01-01  2016-01-01                      0     -464  \n",
       "4                 5   2016-01-01  2016-01-01                      0     -464  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ar'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id          air_store_id  visit_date\n",
       "0  air_00a91d42b08b08d9_2017-04-23  air_00a91d42b08b08d9  2017-04-23\n",
       "1  air_00a91d42b08b08d9_2017-04-24  air_00a91d42b08b08d9  2017-04-24\n",
       "2  air_00a91d42b08b08d9_2017-04-25  air_00a91d42b08b08d9  2017-04-25\n",
       "3  air_00a91d42b08b08d9_2017-04-26  air_00a91d42b08b08d9  2017-04-26\n",
       "4  air_00a91d42b08b08d9_2017-04-27  air_00a91d42b08b08d9  2017-04-27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tes'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(data['tes']['visit_date'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train 他的 最后出现的天是2017-4-22 ，test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-23\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'air_store_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4980ede2a73a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt_begin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2017\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_begin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"air_store_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"left\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"day_gap\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"visit_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdate_gap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_begin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   6387\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6388\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6389\u001b[1;33m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[0;32m   6390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    549\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    550\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                         left_keys.append(left._get_label_or_level_values(\n\u001b[1;32m--> 871\u001b[1;33m                             lk, stacklevel=stacklevel))\n\u001b[0m\u001b[0;32m    872\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'air_store_id'"
     ]
    }
   ],
   "source": [
    "t_begin=date(2017,4, 23)\n",
    "print(t_begin)\n",
    "df_label=data['tes'].merge(data['id'],on=\"air_store_id\",how=\"left\")\n",
    "\n",
    "df_label[\"day_gap\"]=df_label[\"visit_date\"].apply(lambda x:date_gap(x,t_begin))\n",
    "data['tra'][\"day_gap\"]=data['tra'][\"visit_date\"].apply(lambda x:date_gap(x,t_begin))\n",
    "data['ar'][\"day_gap\"] = data['ar'][\"reserve_date\"].apply(lambda x: date_gap(x, t_begin))\n",
    "data['hr'][\"day_gap\"] = data['hr'][\"reserve_date\"].apply(lambda x: date_gap(x, t_begin))\n",
    "\n",
    "\n",
    "\n",
    "df_label=df_label[[\"air_store_id\",\"hpg_store_id\",\"visit_date\",\"day_gap\"]].copy()\n",
    "test=create_features(df_label,data['tra'],data['ar'],data['hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.drop([\"air_store_id\",\"hpg_store_id\",\"visit_date\"], axis=1)\n",
    "test_data = test.drop([\"air_store_id\",\"hpg_store_id\",\"visit_date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "    \n",
    "model1 = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3, n_estimators=200, subsample=0.8, \n",
    "                      max_depth =10)\n",
    "model2 = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "model3 = XGBRegressor(learning_rate=0.2, random_state=3, n_estimators=280, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth =12)\n",
    "\n",
    "model1.fit(train[col], np.log1p(train['visitors'].values))\n",
    "model2.fit(train[col], np.log1p(train['visitors'].values))\n",
    "model3.fit(train[col], np.log1p(train['visitors'].values))\n",
    "\n",
    "preds1 = model1.predict(train[col])\n",
    "preds2 = model2.predict(train[col])\n",
    "preds3 = model3.predict(train[col])\n",
    "\n",
    "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(train['visitors'].values), preds1))\n",
    "print('RMSE KNeighborsRegressor: ', RMSLE(np.log1p(train['visitors'].values), preds2))\n",
    "print('RMSE XGBRegressor: ', RMSLE(np.log1p(train['visitors'].values), preds3))\n",
    "preds1 = model1.predict(test[col])\n",
    "preds2 = model2.predict(test[col])\n",
    "preds3 = model3.predict(test[col])\n",
    "\n",
    "test['visitors'] = 0.3*preds1+0.3*preds2+0.4*preds3\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub1 = test[['id','visitors']].copy()\n",
    "del train; del data;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
