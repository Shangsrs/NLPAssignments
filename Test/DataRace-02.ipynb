{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>291</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>5076</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>7</td>\n",
       "      <td>apr</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>104</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>jul</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-994</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>jul</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2974</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>may</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  age         job   marital  education default  balance housing loan  \\\n",
       "0   1   43  management   married   tertiary      no      291     yes   no   \n",
       "1   2   42  technician  divorced    primary      no     5076     yes   no   \n",
       "2   3   47      admin.   married  secondary      no      104     yes  yes   \n",
       "3   4   28  management    single  secondary      no     -994     yes  yes   \n",
       "4   5   42  technician  divorced  secondary      no     2974     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0   unknown    9   may       150         2     -1         0  unknown  0  \n",
       "1  cellular    7   apr        99         1    251         2    other  0  \n",
       "2  cellular   14   jul        77         2     -1         0  unknown  0  \n",
       "3  cellular   18   jul       174         2     -1         0  unknown  0  \n",
       "4   unknown   21   may       187         5     -1         0  unknown  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/python/datasource/DataRace/'\n",
    "train = pd.read_csv(path + 'input-02/train_set.csv')\n",
    "test = pd.read_csv(path + 'input-02/test_set.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22356.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,  2961.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa0c9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25318</td>\n",
       "      <td>51</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>174</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>29</td>\n",
       "      <td>jul</td>\n",
       "      <td>308</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25319</td>\n",
       "      <td>32</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>6059</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>20</td>\n",
       "      <td>nov</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25320</td>\n",
       "      <td>60</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>30</td>\n",
       "      <td>jul</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25321</td>\n",
       "      <td>32</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>64</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>30</td>\n",
       "      <td>jun</td>\n",
       "      <td>598</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25322</td>\n",
       "      <td>41</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>15</td>\n",
       "      <td>jul</td>\n",
       "      <td>368</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  age         job  marital  education default  balance housing loan  \\\n",
       "0  25318   51   housemaid  married    unknown      no      174      no   no   \n",
       "1  25319   32  management  married   tertiary      no     6059     yes   no   \n",
       "2  25320   60     retired  married    primary      no        0      no   no   \n",
       "3  25321   32     student   single   tertiary      no       64      no   no   \n",
       "4  25322   41   housemaid  married  secondary      no        0     yes  yes   \n",
       "\n",
       "     contact  day month  duration  campaign  pdays  previous poutcome  \n",
       "0  telephone   29   jul       308         3     -1         0  unknown  \n",
       "1   cellular   20   nov       110         2     -1         0  unknown  \n",
       "2  telephone   30   jul       130         3     -1         0  unknown  \n",
       "3   cellular   30   jun       598         4    105         5  failure  \n",
       "4   cellular   15   jul       368         4     -1         0  unknown  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>-0.020171</td>\n",
       "      <td>0.229149</td>\n",
       "      <td>-0.038265</td>\n",
       "      <td>0.065807</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>0.556627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.008465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093740</td>\n",
       "      <td>-0.016070</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>-0.026431</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.029916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.093740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>-0.010419</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.057564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.020171</td>\n",
       "      <td>-0.016070</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031946</td>\n",
       "      <td>0.168830</td>\n",
       "      <td>-0.092892</td>\n",
       "      <td>-0.050706</td>\n",
       "      <td>-0.031886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0.229149</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>-0.031946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087780</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.394746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>-0.038265</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>-0.010419</td>\n",
       "      <td>0.168830</td>\n",
       "      <td>-0.087780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089224</td>\n",
       "      <td>-0.031667</td>\n",
       "      <td>-0.075173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>0.065807</td>\n",
       "      <td>-0.026431</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>-0.092892</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.089224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411688</td>\n",
       "      <td>0.107565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.047028</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>-0.050706</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>-0.031667</td>\n",
       "      <td>0.411688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.556627</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>-0.031886</td>\n",
       "      <td>0.394746</td>\n",
       "      <td>-0.075173</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       age   balance       day  duration  campaign  \\\n",
       "ID        1.000000  0.008465  0.032719 -0.020171  0.229149 -0.038265   \n",
       "age       0.008465  1.000000  0.093740 -0.016070  0.000416  0.006171   \n",
       "balance   0.032719  0.093740  1.000000  0.010245  0.026042 -0.010419   \n",
       "day      -0.020171 -0.016070  0.010245  1.000000 -0.031946  0.168830   \n",
       "duration  0.229149  0.000416  0.026042 -0.031946  1.000000 -0.087780   \n",
       "campaign -0.038265  0.006171 -0.010419  0.168830 -0.087780  1.000000   \n",
       "pdays     0.065807 -0.026431  0.001032 -0.092892  0.000040 -0.089224   \n",
       "previous  0.047028  0.006575  0.015792 -0.050706  0.001315 -0.031667   \n",
       "y         0.556627  0.029916  0.057564 -0.031886  0.394746 -0.075173   \n",
       "\n",
       "             pdays  previous         y  \n",
       "ID        0.065807  0.047028  0.556627  \n",
       "age      -0.026431  0.006575  0.029916  \n",
       "balance   0.001032  0.015792  0.057564  \n",
       "day      -0.092892 -0.050706 -0.031886  \n",
       "duration  0.000040  0.001315  0.394746  \n",
       "campaign -0.089224 -0.031667 -0.075173  \n",
       "pdays     1.000000  0.411688  0.107565  \n",
       "previous  0.411688  1.000000  0.088337  \n",
       "y         0.107565  0.088337  1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22356\n",
       "1     2961\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue-collar      5456\n",
       "management       5296\n",
       "technician       4241\n",
       "admin.           2909\n",
       "services         2342\n",
       "retired          1273\n",
       "self-employed     884\n",
       "entrepreneur      856\n",
       "unemployed        701\n",
       "housemaid         663\n",
       "student           533\n",
       "unknown           163\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.job.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['y'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>291</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>5076</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>7</td>\n",
       "      <td>apr</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>104</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>jul</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-994</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>jul</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2974</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>may</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  age         job   marital  education default  balance housing loan  \\\n",
       "0   1   43  management   married   tertiary      no      291     yes   no   \n",
       "1   2   42  technician  divorced    primary      no     5076     yes   no   \n",
       "2   3   47      admin.   married  secondary      no      104     yes  yes   \n",
       "3   4   28  management    single  secondary      no     -994     yes  yes   \n",
       "4   5   42  technician  divorced  secondary      no     2974     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0   unknown    9   may       150         2     -1         0  unknown  0  \n",
       "1  cellular    7   apr        99         1    251         2    other  0  \n",
       "2  cellular   14   jul        77         2     -1         0  unknown  0  \n",
       "3  cellular   18   jul       174         2     -1         0  unknown  0  \n",
       "4   unknown   21   may       187         5     -1         0  unknown  0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train.append(test).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25317, 10852, 36169)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install --user catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "import catboost as cbt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler as std\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "import scipy.spatial.distance as dist\n",
    "\n",
    "from collections import Counter\n",
    "from statistics import mode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "from itertools import product\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321b5be303ee4ab0bd5af77f880bf004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cat_col = [i for i in data.select_dtypes(object).columns if i not in ['ID','y']]\n",
    "for i in tqdm_notebook(cat_col):\n",
    "    lbl = LabelEncoder()\n",
    "    data['count_' + i] = data.groupby([i])[i].transform('count')\n",
    "    data[i] = lbl.fit_transform(data[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'poutcome']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>count_job</th>\n",
       "      <th>count_marital</th>\n",
       "      <th>count_education</th>\n",
       "      <th>count_default</th>\n",
       "      <th>count_housing</th>\n",
       "      <th>count_loan</th>\n",
       "      <th>count_contact</th>\n",
       "      <th>count_month</th>\n",
       "      <th>count_poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7595</td>\n",
       "      <td>21857</td>\n",
       "      <td>10654</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>30363</td>\n",
       "      <td>10393</td>\n",
       "      <td>10957</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6083</td>\n",
       "      <td>4140</td>\n",
       "      <td>5493</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>30363</td>\n",
       "      <td>23437</td>\n",
       "      <td>2365</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4124</td>\n",
       "      <td>21857</td>\n",
       "      <td>18509</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>5806</td>\n",
       "      <td>23437</td>\n",
       "      <td>5569</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7595</td>\n",
       "      <td>10172</td>\n",
       "      <td>18509</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>5806</td>\n",
       "      <td>23437</td>\n",
       "      <td>5569</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6083</td>\n",
       "      <td>4140</td>\n",
       "      <td>18509</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>30363</td>\n",
       "      <td>10393</td>\n",
       "      <td>10957</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   1   43    4        1          2        0      291        1     0        2   \n",
       "1   2   42    9        0          0        0     5076        1     0        0   \n",
       "2   3   47    0        1          1        0      104        1     1        0   \n",
       "3   4   28    4        2          1        0     -994        1     1        0   \n",
       "4   5   42    9        0          1        0     2974        1     0        2   \n",
       "\n",
       "   ...  y  count_job  count_marital  count_education  count_default  \\\n",
       "0  ...  0       7595          21857            10654          35524   \n",
       "1  ...  0       6083           4140             5493          35524   \n",
       "2  ...  0       4124          21857            18509          35524   \n",
       "3  ...  0       7595          10172            18509          35524   \n",
       "4  ...  0       6083           4140            18509          35524   \n",
       "\n",
       "   count_housing  count_loan  count_contact  count_month  count_poutcome  \n",
       "0          19959       30363          10393        10957           29554  \n",
       "1          19959       30363          23437         2365            1475  \n",
       "2          19959        5806          23437         5569           29554  \n",
       "3          19959        5806          23437         5569           29554  \n",
       "4          19959       30363          10393        10957           29554  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day',\n",
       " 'month',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'count_job',\n",
       " 'count_marital',\n",
       " 'count_education',\n",
       " 'count_default',\n",
       " 'count_housing',\n",
       " 'count_loan',\n",
       " 'count_contact',\n",
       " 'count_month',\n",
       " 'count_poutcome']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = [i for i in data.columns if i not in['ID', 'y']]\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=30, reg_alpha=0, reg_lambda=0.,\n",
    "                          max_depth=-1, n_estimators=1500, objective='binary',metric='auc',\n",
    "                          subsample=0.095, colsample_bytree=0.7,subsample_freq=1,\n",
    "                          learning_rate=0.2, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_x = data[data['y'] != -1][feats]\n",
    "train_y = data[data['y'] != -1]['y']\n",
    "test_x = data[data['y'] == -1][feats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>count_job</th>\n",
       "      <th>count_marital</th>\n",
       "      <th>count_education</th>\n",
       "      <th>count_default</th>\n",
       "      <th>count_housing</th>\n",
       "      <th>count_loan</th>\n",
       "      <th>count_contact</th>\n",
       "      <th>count_month</th>\n",
       "      <th>count_poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7595</td>\n",
       "      <td>21857</td>\n",
       "      <td>10654</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>30363</td>\n",
       "      <td>10393</td>\n",
       "      <td>10957</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6083</td>\n",
       "      <td>4140</td>\n",
       "      <td>5493</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>30363</td>\n",
       "      <td>23437</td>\n",
       "      <td>2365</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4124</td>\n",
       "      <td>21857</td>\n",
       "      <td>18509</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>5806</td>\n",
       "      <td>23437</td>\n",
       "      <td>5569</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7595</td>\n",
       "      <td>10172</td>\n",
       "      <td>18509</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>5806</td>\n",
       "      <td>23437</td>\n",
       "      <td>5569</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6083</td>\n",
       "      <td>4140</td>\n",
       "      <td>18509</td>\n",
       "      <td>35524</td>\n",
       "      <td>19959</td>\n",
       "      <td>30363</td>\n",
       "      <td>10393</td>\n",
       "      <td>10957</td>\n",
       "      <td>29554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   43    4        1          2        0      291        1     0        2   \n",
       "1   42    9        0          0        0     5076        1     0        0   \n",
       "2   47    0        1          1        0      104        1     1        0   \n",
       "3   28    4        2          1        0     -994        1     1        0   \n",
       "4   42    9        0          1        0     2974        1     0        2   \n",
       "\n",
       "   day  ...  poutcome  count_job  count_marital  count_education  \\\n",
       "0    9  ...         3       7595          21857            10654   \n",
       "1    7  ...         1       6083           4140             5493   \n",
       "2   14  ...         3       4124          21857            18509   \n",
       "3   18  ...         3       7595          10172            18509   \n",
       "4   21  ...         3       6083           4140            18509   \n",
       "\n",
       "   count_default  count_housing  count_loan  count_contact  count_month  \\\n",
       "0          35524          19959       30363          10393        10957   \n",
       "1          35524          19959       30363          23437         2365   \n",
       "2          35524          19959        5806          23437         5569   \n",
       "3          35524          19959        5806          23437         5569   \n",
       "4          35524          19959       30363          10393        10957   \n",
       "\n",
       "   count_poutcome  \n",
       "0           29554  \n",
       "1            1475  \n",
       "2           29554  \n",
       "3           29554  \n",
       "4           29554  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y)\n",
    "test_pre = model.predict_proba(test_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10852"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = data[data['y'] == -1][['ID']]\n",
    "pre['pred']=test_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25317</th>\n",
       "      <td>25318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25318</th>\n",
       "      <td>25319</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25319</th>\n",
       "      <td>25320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25320</th>\n",
       "      <td>25321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25321</th>\n",
       "      <td>25322</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  pred\n",
       "25317  25318   0.0\n",
       "25318  25319   0.0\n",
       "25319  25320   0.0\n",
       "25320  25321   0.0\n",
       "25321  25322   0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.726203\tvalid_1's auc: 0.717626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.872518\tvalid_1's auc: 0.855064\n",
      "[3]\ttraining's auc: 0.878135\tvalid_1's auc: 0.861229\n",
      "[4]\ttraining's auc: 0.880192\tvalid_1's auc: 0.863334\n",
      "[5]\ttraining's auc: 0.90129\tvalid_1's auc: 0.885359\n",
      "[6]\ttraining's auc: 0.911643\tvalid_1's auc: 0.895622\n",
      "[7]\ttraining's auc: 0.911451\tvalid_1's auc: 0.894246\n",
      "[8]\ttraining's auc: 0.916884\tvalid_1's auc: 0.898221\n",
      "[9]\ttraining's auc: 0.916837\tvalid_1's auc: 0.895186\n",
      "[10]\ttraining's auc: 0.916832\tvalid_1's auc: 0.891272\n",
      "[11]\ttraining's auc: 0.920733\tvalid_1's auc: 0.899557\n",
      "[12]\ttraining's auc: 0.922175\tvalid_1's auc: 0.901855\n",
      "[13]\ttraining's auc: 0.923235\tvalid_1's auc: 0.901225\n",
      "[14]\ttraining's auc: 0.922954\tvalid_1's auc: 0.900556\n",
      "[15]\ttraining's auc: 0.925379\tvalid_1's auc: 0.903728\n",
      "[16]\ttraining's auc: 0.926181\tvalid_1's auc: 0.903097\n",
      "[17]\ttraining's auc: 0.926304\tvalid_1's auc: 0.90459\n",
      "[18]\ttraining's auc: 0.926755\tvalid_1's auc: 0.90628\n",
      "[19]\ttraining's auc: 0.926959\tvalid_1's auc: 0.905404\n",
      "[20]\ttraining's auc: 0.927909\tvalid_1's auc: 0.907065\n",
      "[21]\ttraining's auc: 0.928281\tvalid_1's auc: 0.905554\n",
      "[22]\ttraining's auc: 0.928596\tvalid_1's auc: 0.905479\n",
      "[23]\ttraining's auc: 0.928491\tvalid_1's auc: 0.903612\n",
      "[24]\ttraining's auc: 0.928163\tvalid_1's auc: 0.902116\n",
      "[25]\ttraining's auc: 0.928312\tvalid_1's auc: 0.901467\n",
      "[26]\ttraining's auc: 0.928364\tvalid_1's auc: 0.901061\n",
      "[27]\ttraining's auc: 0.929865\tvalid_1's auc: 0.900863\n",
      "[28]\ttraining's auc: 0.930671\tvalid_1's auc: 0.901931\n",
      "[29]\ttraining's auc: 0.931558\tvalid_1's auc: 0.90301\n",
      "[30]\ttraining's auc: 0.931374\tvalid_1's auc: 0.90282\n",
      "[31]\ttraining's auc: 0.93106\tvalid_1's auc: 0.900969\n",
      "[32]\ttraining's auc: 0.93101\tvalid_1's auc: 0.900204\n",
      "[33]\ttraining's auc: 0.929992\tvalid_1's auc: 0.898788\n",
      "[34]\ttraining's auc: 0.931243\tvalid_1's auc: 0.897925\n",
      "[35]\ttraining's auc: 0.931718\tvalid_1's auc: 0.895544\n",
      "[36]\ttraining's auc: 0.931695\tvalid_1's auc: 0.897669\n",
      "[37]\ttraining's auc: 0.931563\tvalid_1's auc: 0.895443\n",
      "[38]\ttraining's auc: 0.931962\tvalid_1's auc: 0.896459\n",
      "[39]\ttraining's auc: 0.931644\tvalid_1's auc: 0.896551\n",
      "[40]\ttraining's auc: 0.931724\tvalid_1's auc: 0.896432\n",
      "[41]\ttraining's auc: 0.931328\tvalid_1's auc: 0.892249\n",
      "[42]\ttraining's auc: 0.932078\tvalid_1's auc: 0.891457\n",
      "[43]\ttraining's auc: 0.93266\tvalid_1's auc: 0.891317\n",
      "[44]\ttraining's auc: 0.933022\tvalid_1's auc: 0.891843\n",
      "[45]\ttraining's auc: 0.932635\tvalid_1's auc: 0.889982\n",
      "[46]\ttraining's auc: 0.932791\tvalid_1's auc: 0.889649\n",
      "[47]\ttraining's auc: 0.932533\tvalid_1's auc: 0.887806\n",
      "[48]\ttraining's auc: 0.933263\tvalid_1's auc: 0.887565\n",
      "[49]\ttraining's auc: 0.928221\tvalid_1's auc: 0.877503\n",
      "[50]\ttraining's auc: 0.929075\tvalid_1's auc: 0.878266\n",
      "[51]\ttraining's auc: 0.929978\tvalid_1's auc: 0.87884\n",
      "[52]\ttraining's auc: 0.929908\tvalid_1's auc: 0.879601\n",
      "[53]\ttraining's auc: 0.930518\tvalid_1's auc: 0.880767\n",
      "[54]\ttraining's auc: 0.931253\tvalid_1's auc: 0.882672\n",
      "[55]\ttraining's auc: 0.931172\tvalid_1's auc: 0.882428\n",
      "[56]\ttraining's auc: 0.931088\tvalid_1's auc: 0.880053\n",
      "[57]\ttraining's auc: 0.933142\tvalid_1's auc: 0.884357\n",
      "[58]\ttraining's auc: 0.932886\tvalid_1's auc: 0.880866\n",
      "[59]\ttraining's auc: 0.933526\tvalid_1's auc: 0.881328\n",
      "[60]\ttraining's auc: 0.934301\tvalid_1's auc: 0.880764\n",
      "[61]\ttraining's auc: 0.935181\tvalid_1's auc: 0.882764\n",
      "[62]\ttraining's auc: 0.936409\tvalid_1's auc: 0.883656\n",
      "[63]\ttraining's auc: 0.934659\tvalid_1's auc: 0.876994\n",
      "[64]\ttraining's auc: 0.935814\tvalid_1's auc: 0.877785\n",
      "[65]\ttraining's auc: 0.936123\tvalid_1's auc: 0.878856\n",
      "[66]\ttraining's auc: 0.936913\tvalid_1's auc: 0.880872\n",
      "[67]\ttraining's auc: 0.937734\tvalid_1's auc: 0.883155\n",
      "[68]\ttraining's auc: 0.934382\tvalid_1's auc: 0.876567\n",
      "[69]\ttraining's auc: 0.934922\tvalid_1's auc: 0.876673\n",
      "[70]\ttraining's auc: 0.934965\tvalid_1's auc: 0.876617\n",
      "[71]\ttraining's auc: 0.935505\tvalid_1's auc: 0.87661\n",
      "[72]\ttraining's auc: 0.931672\tvalid_1's auc: 0.868103\n",
      "[73]\ttraining's auc: 0.93293\tvalid_1's auc: 0.868258\n",
      "[74]\ttraining's auc: 0.932937\tvalid_1's auc: 0.867206\n",
      "[75]\ttraining's auc: 0.93433\tvalid_1's auc: 0.868773\n",
      "[76]\ttraining's auc: 0.936154\tvalid_1's auc: 0.872116\n",
      "[77]\ttraining's auc: 0.936716\tvalid_1's auc: 0.873408\n",
      "[78]\ttraining's auc: 0.933848\tvalid_1's auc: 0.867541\n",
      "[79]\ttraining's auc: 0.933786\tvalid_1's auc: 0.867252\n",
      "[80]\ttraining's auc: 0.933564\tvalid_1's auc: 0.867896\n",
      "[81]\ttraining's auc: 0.9332\tvalid_1's auc: 0.865976\n",
      "[82]\ttraining's auc: 0.932452\tvalid_1's auc: 0.865206\n",
      "[83]\ttraining's auc: 0.931338\tvalid_1's auc: 0.861066\n",
      "[84]\ttraining's auc: 0.932441\tvalid_1's auc: 0.862778\n",
      "[85]\ttraining's auc: 0.927083\tvalid_1's auc: 0.857331\n",
      "[86]\ttraining's auc: 0.927753\tvalid_1's auc: 0.859223\n",
      "[87]\ttraining's auc: 0.930304\tvalid_1's auc: 0.861859\n",
      "[88]\ttraining's auc: 0.930329\tvalid_1's auc: 0.860854\n",
      "[89]\ttraining's auc: 0.93104\tvalid_1's auc: 0.862859\n",
      "[90]\ttraining's auc: 0.922454\tvalid_1's auc: 0.856817\n",
      "[91]\ttraining's auc: 0.924857\tvalid_1's auc: 0.860371\n",
      "[92]\ttraining's auc: 0.927213\tvalid_1's auc: 0.862821\n",
      "[93]\ttraining's auc: 0.922904\tvalid_1's auc: 0.857565\n",
      "[94]\ttraining's auc: 0.923107\tvalid_1's auc: 0.856444\n",
      "[95]\ttraining's auc: 0.923709\tvalid_1's auc: 0.855655\n",
      "[96]\ttraining's auc: 0.922649\tvalid_1's auc: 0.850304\n",
      "[97]\ttraining's auc: 0.900601\tvalid_1's auc: 0.82855\n",
      "[98]\ttraining's auc: 0.899314\tvalid_1's auc: 0.821936\n",
      "[99]\ttraining's auc: 0.882745\tvalid_1's auc: 0.804328\n",
      "[100]\ttraining's auc: 0.87467\tvalid_1's auc: 0.793646\n",
      "[101]\ttraining's auc: 0.870851\tvalid_1's auc: 0.799393\n",
      "[102]\ttraining's auc: 0.856297\tvalid_1's auc: 0.787066\n",
      "[103]\ttraining's auc: 0.849975\tvalid_1's auc: 0.786015\n",
      "[104]\ttraining's auc: 0.857329\tvalid_1's auc: 0.797633\n",
      "[105]\ttraining's auc: 0.839808\tvalid_1's auc: 0.784943\n",
      "[106]\ttraining's auc: 0.856791\tvalid_1's auc: 0.802747\n",
      "[107]\ttraining's auc: 0.856423\tvalid_1's auc: 0.812458\n",
      "[108]\ttraining's auc: 0.859325\tvalid_1's auc: 0.810315\n",
      "[109]\ttraining's auc: 0.864082\tvalid_1's auc: 0.814248\n",
      "[110]\ttraining's auc: 0.847347\tvalid_1's auc: 0.795499\n",
      "[111]\ttraining's auc: 0.844124\tvalid_1's auc: 0.806295\n",
      "[112]\ttraining's auc: 0.824017\tvalid_1's auc: 0.791053\n",
      "[113]\ttraining's auc: 0.830245\tvalid_1's auc: 0.791776\n",
      "[114]\ttraining's auc: 0.844587\tvalid_1's auc: 0.803915\n",
      "[115]\ttraining's auc: 0.837702\tvalid_1's auc: 0.797677\n",
      "[116]\ttraining's auc: 0.831364\tvalid_1's auc: 0.795111\n",
      "[117]\ttraining's auc: 0.829522\tvalid_1's auc: 0.790009\n",
      "[118]\ttraining's auc: 0.830982\tvalid_1's auc: 0.792693\n",
      "[119]\ttraining's auc: 0.828474\tvalid_1's auc: 0.789524\n",
      "[120]\ttraining's auc: 0.796433\tvalid_1's auc: 0.75592\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.927909\tvalid_1's auc: 0.907065\n",
      "[1]\ttraining's auc: 0.850892\tvalid_1's auc: 0.868168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.889019\tvalid_1's auc: 0.894119\n",
      "[3]\ttraining's auc: 0.89689\tvalid_1's auc: 0.903506\n",
      "[4]\ttraining's auc: 0.896979\tvalid_1's auc: 0.904106\n",
      "[5]\ttraining's auc: 0.904847\tvalid_1's auc: 0.905696\n",
      "[6]\ttraining's auc: 0.908884\tvalid_1's auc: 0.906575\n",
      "[7]\ttraining's auc: 0.914565\tvalid_1's auc: 0.912032\n",
      "[8]\ttraining's auc: 0.916837\tvalid_1's auc: 0.913191\n",
      "[9]\ttraining's auc: 0.919869\tvalid_1's auc: 0.916375\n",
      "[10]\ttraining's auc: 0.921922\tvalid_1's auc: 0.915818\n",
      "[11]\ttraining's auc: 0.923085\tvalid_1's auc: 0.917523\n",
      "[12]\ttraining's auc: 0.924253\tvalid_1's auc: 0.919445\n",
      "[13]\ttraining's auc: 0.924825\tvalid_1's auc: 0.919809\n",
      "[14]\ttraining's auc: 0.926585\tvalid_1's auc: 0.922065\n",
      "[15]\ttraining's auc: 0.927049\tvalid_1's auc: 0.921018\n",
      "[16]\ttraining's auc: 0.927679\tvalid_1's auc: 0.919997\n",
      "[17]\ttraining's auc: 0.927736\tvalid_1's auc: 0.91861\n",
      "[18]\ttraining's auc: 0.927842\tvalid_1's auc: 0.916971\n",
      "[19]\ttraining's auc: 0.92778\tvalid_1's auc: 0.916398\n",
      "[20]\ttraining's auc: 0.928284\tvalid_1's auc: 0.916241\n",
      "[21]\ttraining's auc: 0.928424\tvalid_1's auc: 0.9182\n",
      "[22]\ttraining's auc: 0.928897\tvalid_1's auc: 0.91761\n",
      "[23]\ttraining's auc: 0.928753\tvalid_1's auc: 0.915167\n",
      "[24]\ttraining's auc: 0.928512\tvalid_1's auc: 0.914801\n",
      "[25]\ttraining's auc: 0.929281\tvalid_1's auc: 0.913553\n",
      "[26]\ttraining's auc: 0.929427\tvalid_1's auc: 0.913286\n",
      "[27]\ttraining's auc: 0.93045\tvalid_1's auc: 0.91525\n",
      "[28]\ttraining's auc: 0.930722\tvalid_1's auc: 0.915853\n",
      "[29]\ttraining's auc: 0.93115\tvalid_1's auc: 0.916823\n",
      "[30]\ttraining's auc: 0.931244\tvalid_1's auc: 0.914744\n",
      "[31]\ttraining's auc: 0.931288\tvalid_1's auc: 0.913486\n",
      "[32]\ttraining's auc: 0.931542\tvalid_1's auc: 0.91283\n",
      "[33]\ttraining's auc: 0.932035\tvalid_1's auc: 0.913021\n",
      "[34]\ttraining's auc: 0.931938\tvalid_1's auc: 0.91341\n",
      "[35]\ttraining's auc: 0.932365\tvalid_1's auc: 0.912217\n",
      "[36]\ttraining's auc: 0.932936\tvalid_1's auc: 0.913469\n",
      "[37]\ttraining's auc: 0.931911\tvalid_1's auc: 0.913472\n",
      "[38]\ttraining's auc: 0.932042\tvalid_1's auc: 0.91353\n",
      "[39]\ttraining's auc: 0.932379\tvalid_1's auc: 0.911407\n",
      "[40]\ttraining's auc: 0.932033\tvalid_1's auc: 0.910008\n",
      "[41]\ttraining's auc: 0.931818\tvalid_1's auc: 0.908882\n",
      "[42]\ttraining's auc: 0.931468\tvalid_1's auc: 0.906811\n",
      "[43]\ttraining's auc: 0.930969\tvalid_1's auc: 0.905327\n",
      "[44]\ttraining's auc: 0.92974\tvalid_1's auc: 0.904208\n",
      "[45]\ttraining's auc: 0.930629\tvalid_1's auc: 0.904152\n",
      "[46]\ttraining's auc: 0.93155\tvalid_1's auc: 0.904407\n",
      "[47]\ttraining's auc: 0.931779\tvalid_1's auc: 0.904033\n",
      "[48]\ttraining's auc: 0.931626\tvalid_1's auc: 0.903086\n",
      "[49]\ttraining's auc: 0.931642\tvalid_1's auc: 0.904325\n",
      "[50]\ttraining's auc: 0.927947\tvalid_1's auc: 0.896873\n",
      "[51]\ttraining's auc: 0.928782\tvalid_1's auc: 0.897606\n",
      "[52]\ttraining's auc: 0.929682\tvalid_1's auc: 0.89917\n",
      "[53]\ttraining's auc: 0.929778\tvalid_1's auc: 0.896602\n",
      "[54]\ttraining's auc: 0.930322\tvalid_1's auc: 0.896312\n",
      "[55]\ttraining's auc: 0.928232\tvalid_1's auc: 0.892936\n",
      "[56]\ttraining's auc: 0.929276\tvalid_1's auc: 0.894008\n",
      "[57]\ttraining's auc: 0.929064\tvalid_1's auc: 0.893234\n",
      "[58]\ttraining's auc: 0.930182\tvalid_1's auc: 0.894474\n",
      "[59]\ttraining's auc: 0.93097\tvalid_1's auc: 0.897513\n",
      "[60]\ttraining's auc: 0.931418\tvalid_1's auc: 0.896936\n",
      "[61]\ttraining's auc: 0.931388\tvalid_1's auc: 0.895175\n",
      "[62]\ttraining's auc: 0.932008\tvalid_1's auc: 0.895522\n",
      "[63]\ttraining's auc: 0.931923\tvalid_1's auc: 0.895834\n",
      "[64]\ttraining's auc: 0.932113\tvalid_1's auc: 0.896276\n",
      "[65]\ttraining's auc: 0.932452\tvalid_1's auc: 0.89546\n",
      "[66]\ttraining's auc: 0.931993\tvalid_1's auc: 0.895103\n",
      "[67]\ttraining's auc: 0.932115\tvalid_1's auc: 0.894517\n",
      "[68]\ttraining's auc: 0.924905\tvalid_1's auc: 0.886453\n",
      "[69]\ttraining's auc: 0.931097\tvalid_1's auc: 0.894423\n",
      "[70]\ttraining's auc: 0.933133\tvalid_1's auc: 0.894227\n",
      "[71]\ttraining's auc: 0.932083\tvalid_1's auc: 0.895371\n",
      "[72]\ttraining's auc: 0.931899\tvalid_1's auc: 0.894697\n",
      "[73]\ttraining's auc: 0.932547\tvalid_1's auc: 0.895234\n",
      "[74]\ttraining's auc: 0.932661\tvalid_1's auc: 0.893082\n",
      "[75]\ttraining's auc: 0.933353\tvalid_1's auc: 0.892661\n",
      "[76]\ttraining's auc: 0.933619\tvalid_1's auc: 0.891662\n",
      "[77]\ttraining's auc: 0.933233\tvalid_1's auc: 0.89055\n",
      "[78]\ttraining's auc: 0.932703\tvalid_1's auc: 0.887643\n",
      "[79]\ttraining's auc: 0.932344\tvalid_1's auc: 0.886416\n",
      "[80]\ttraining's auc: 0.926973\tvalid_1's auc: 0.873489\n",
      "[81]\ttraining's auc: 0.926572\tvalid_1's auc: 0.874914\n",
      "[82]\ttraining's auc: 0.920119\tvalid_1's auc: 0.867954\n",
      "[83]\ttraining's auc: 0.926301\tvalid_1's auc: 0.876652\n",
      "[84]\ttraining's auc: 0.927903\tvalid_1's auc: 0.877113\n",
      "[85]\ttraining's auc: 0.927659\tvalid_1's auc: 0.876703\n",
      "[86]\ttraining's auc: 0.927828\tvalid_1's auc: 0.876765\n",
      "[87]\ttraining's auc: 0.928588\tvalid_1's auc: 0.877937\n",
      "[88]\ttraining's auc: 0.926017\tvalid_1's auc: 0.875772\n",
      "[89]\ttraining's auc: 0.926782\tvalid_1's auc: 0.877068\n",
      "[90]\ttraining's auc: 0.918828\tvalid_1's auc: 0.870324\n",
      "[91]\ttraining's auc: 0.920597\tvalid_1's auc: 0.874356\n",
      "[92]\ttraining's auc: 0.923757\tvalid_1's auc: 0.880354\n",
      "[93]\ttraining's auc: 0.923692\tvalid_1's auc: 0.880217\n",
      "[94]\ttraining's auc: 0.923665\tvalid_1's auc: 0.881972\n",
      "[95]\ttraining's auc: 0.923224\tvalid_1's auc: 0.881246\n",
      "[96]\ttraining's auc: 0.926086\tvalid_1's auc: 0.885924\n",
      "[97]\ttraining's auc: 0.927612\tvalid_1's auc: 0.885874\n",
      "[98]\ttraining's auc: 0.924267\tvalid_1's auc: 0.88289\n",
      "[99]\ttraining's auc: 0.923581\tvalid_1's auc: 0.881482\n",
      "[100]\ttraining's auc: 0.924164\tvalid_1's auc: 0.88067\n",
      "[101]\ttraining's auc: 0.92617\tvalid_1's auc: 0.881831\n",
      "[102]\ttraining's auc: 0.926021\tvalid_1's auc: 0.882404\n",
      "[103]\ttraining's auc: 0.926007\tvalid_1's auc: 0.880988\n",
      "[104]\ttraining's auc: 0.922351\tvalid_1's auc: 0.87776\n",
      "[105]\ttraining's auc: 0.91509\tvalid_1's auc: 0.868861\n",
      "[106]\ttraining's auc: 0.915207\tvalid_1's auc: 0.87199\n",
      "[107]\ttraining's auc: 0.915\tvalid_1's auc: 0.871189\n",
      "[108]\ttraining's auc: 0.918375\tvalid_1's auc: 0.873855\n",
      "[109]\ttraining's auc: 0.919315\tvalid_1's auc: 0.875302\n",
      "[110]\ttraining's auc: 0.909225\tvalid_1's auc: 0.871249\n",
      "[111]\ttraining's auc: 0.908019\tvalid_1's auc: 0.868583\n",
      "[112]\ttraining's auc: 0.914298\tvalid_1's auc: 0.872738\n",
      "[113]\ttraining's auc: 0.914325\tvalid_1's auc: 0.873082\n",
      "[114]\ttraining's auc: 0.912565\tvalid_1's auc: 0.871392\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.926585\tvalid_1's auc: 0.922065\n",
      "[1]\ttraining's auc: 0.860002\tvalid_1's auc: 0.852788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.86737\tvalid_1's auc: 0.848722\n",
      "[3]\ttraining's auc: 0.877533\tvalid_1's auc: 0.87285\n",
      "[4]\ttraining's auc: 0.89916\tvalid_1's auc: 0.896535\n",
      "[5]\ttraining's auc: 0.906437\tvalid_1's auc: 0.902174\n",
      "[6]\ttraining's auc: 0.908951\tvalid_1's auc: 0.903343\n",
      "[7]\ttraining's auc: 0.908522\tvalid_1's auc: 0.899648\n",
      "[8]\ttraining's auc: 0.912947\tvalid_1's auc: 0.906749\n",
      "[9]\ttraining's auc: 0.918024\tvalid_1's auc: 0.912458\n",
      "[10]\ttraining's auc: 0.918028\tvalid_1's auc: 0.912856\n",
      "[11]\ttraining's auc: 0.920815\tvalid_1's auc: 0.91338\n",
      "[12]\ttraining's auc: 0.922867\tvalid_1's auc: 0.916529\n",
      "[13]\ttraining's auc: 0.92298\tvalid_1's auc: 0.916877\n",
      "[14]\ttraining's auc: 0.924075\tvalid_1's auc: 0.916522\n",
      "[15]\ttraining's auc: 0.92374\tvalid_1's auc: 0.914836\n",
      "[16]\ttraining's auc: 0.924171\tvalid_1's auc: 0.915948\n",
      "[17]\ttraining's auc: 0.925047\tvalid_1's auc: 0.915865\n",
      "[18]\ttraining's auc: 0.924994\tvalid_1's auc: 0.915963\n",
      "[19]\ttraining's auc: 0.926243\tvalid_1's auc: 0.917278\n",
      "[20]\ttraining's auc: 0.928057\tvalid_1's auc: 0.919545\n",
      "[21]\ttraining's auc: 0.92898\tvalid_1's auc: 0.920271\n",
      "[22]\ttraining's auc: 0.929017\tvalid_1's auc: 0.919692\n",
      "[23]\ttraining's auc: 0.928781\tvalid_1's auc: 0.920153\n",
      "[24]\ttraining's auc: 0.929568\tvalid_1's auc: 0.920273\n",
      "[25]\ttraining's auc: 0.930411\tvalid_1's auc: 0.920533\n",
      "[26]\ttraining's auc: 0.931302\tvalid_1's auc: 0.921739\n",
      "[27]\ttraining's auc: 0.931714\tvalid_1's auc: 0.921477\n",
      "[28]\ttraining's auc: 0.931701\tvalid_1's auc: 0.921283\n",
      "[29]\ttraining's auc: 0.932053\tvalid_1's auc: 0.920823\n",
      "[30]\ttraining's auc: 0.931848\tvalid_1's auc: 0.920088\n",
      "[31]\ttraining's auc: 0.931895\tvalid_1's auc: 0.918186\n",
      "[32]\ttraining's auc: 0.932324\tvalid_1's auc: 0.918305\n",
      "[33]\ttraining's auc: 0.931929\tvalid_1's auc: 0.917241\n",
      "[34]\ttraining's auc: 0.931736\tvalid_1's auc: 0.91862\n",
      "[35]\ttraining's auc: 0.931455\tvalid_1's auc: 0.917418\n",
      "[36]\ttraining's auc: 0.932376\tvalid_1's auc: 0.916587\n",
      "[37]\ttraining's auc: 0.93262\tvalid_1's auc: 0.91605\n",
      "[38]\ttraining's auc: 0.932791\tvalid_1's auc: 0.916756\n",
      "[39]\ttraining's auc: 0.932675\tvalid_1's auc: 0.916104\n",
      "[40]\ttraining's auc: 0.932816\tvalid_1's auc: 0.915305\n",
      "[41]\ttraining's auc: 0.9323\tvalid_1's auc: 0.914877\n",
      "[42]\ttraining's auc: 0.931747\tvalid_1's auc: 0.911783\n",
      "[43]\ttraining's auc: 0.932205\tvalid_1's auc: 0.90965\n",
      "[44]\ttraining's auc: 0.932278\tvalid_1's auc: 0.908595\n",
      "[45]\ttraining's auc: 0.932123\tvalid_1's auc: 0.906969\n",
      "[46]\ttraining's auc: 0.932754\tvalid_1's auc: 0.908172\n",
      "[47]\ttraining's auc: 0.93329\tvalid_1's auc: 0.908632\n",
      "[48]\ttraining's auc: 0.933712\tvalid_1's auc: 0.907632\n",
      "[49]\ttraining's auc: 0.933594\tvalid_1's auc: 0.907027\n",
      "[50]\ttraining's auc: 0.932893\tvalid_1's auc: 0.904458\n",
      "[51]\ttraining's auc: 0.932622\tvalid_1's auc: 0.904658\n",
      "[52]\ttraining's auc: 0.93336\tvalid_1's auc: 0.905874\n",
      "[53]\ttraining's auc: 0.93453\tvalid_1's auc: 0.906747\n",
      "[54]\ttraining's auc: 0.933945\tvalid_1's auc: 0.906041\n",
      "[55]\ttraining's auc: 0.933982\tvalid_1's auc: 0.904481\n",
      "[56]\ttraining's auc: 0.934801\tvalid_1's auc: 0.906823\n",
      "[57]\ttraining's auc: 0.932353\tvalid_1's auc: 0.900815\n",
      "[58]\ttraining's auc: 0.93337\tvalid_1's auc: 0.901599\n",
      "[59]\ttraining's auc: 0.933201\tvalid_1's auc: 0.899995\n",
      "[60]\ttraining's auc: 0.93457\tvalid_1's auc: 0.900978\n",
      "[61]\ttraining's auc: 0.935146\tvalid_1's auc: 0.902653\n",
      "[62]\ttraining's auc: 0.934984\tvalid_1's auc: 0.900893\n",
      "[63]\ttraining's auc: 0.930929\tvalid_1's auc: 0.895699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\ttraining's auc: 0.931492\tvalid_1's auc: 0.895416\n",
      "[65]\ttraining's auc: 0.932108\tvalid_1's auc: 0.895204\n",
      "[66]\ttraining's auc: 0.931796\tvalid_1's auc: 0.894605\n",
      "[67]\ttraining's auc: 0.932388\tvalid_1's auc: 0.895276\n",
      "[68]\ttraining's auc: 0.93244\tvalid_1's auc: 0.89404\n",
      "[69]\ttraining's auc: 0.933163\tvalid_1's auc: 0.89394\n",
      "[70]\ttraining's auc: 0.932711\tvalid_1's auc: 0.891033\n",
      "[71]\ttraining's auc: 0.933236\tvalid_1's auc: 0.890981\n",
      "[72]\ttraining's auc: 0.933772\tvalid_1's auc: 0.888972\n",
      "[73]\ttraining's auc: 0.934571\tvalid_1's auc: 0.889662\n",
      "[74]\ttraining's auc: 0.935625\tvalid_1's auc: 0.892068\n",
      "[75]\ttraining's auc: 0.936137\tvalid_1's auc: 0.892435\n",
      "[76]\ttraining's auc: 0.936111\tvalid_1's auc: 0.891628\n",
      "[77]\ttraining's auc: 0.934792\tvalid_1's auc: 0.88957\n",
      "[78]\ttraining's auc: 0.935872\tvalid_1's auc: 0.890036\n",
      "[79]\ttraining's auc: 0.93621\tvalid_1's auc: 0.891762\n",
      "[80]\ttraining's auc: 0.935698\tvalid_1's auc: 0.888879\n",
      "[81]\ttraining's auc: 0.936425\tvalid_1's auc: 0.890653\n",
      "[82]\ttraining's auc: 0.93616\tvalid_1's auc: 0.890403\n",
      "[83]\ttraining's auc: 0.933586\tvalid_1's auc: 0.886144\n",
      "[84]\ttraining's auc: 0.931865\tvalid_1's auc: 0.881904\n",
      "[85]\ttraining's auc: 0.933417\tvalid_1's auc: 0.883048\n",
      "[86]\ttraining's auc: 0.924988\tvalid_1's auc: 0.878571\n",
      "[87]\ttraining's auc: 0.927821\tvalid_1's auc: 0.879634\n",
      "[88]\ttraining's auc: 0.916863\tvalid_1's auc: 0.870102\n",
      "[89]\ttraining's auc: 0.913462\tvalid_1's auc: 0.86488\n",
      "[90]\ttraining's auc: 0.907052\tvalid_1's auc: 0.854593\n",
      "[91]\ttraining's auc: 0.913734\tvalid_1's auc: 0.862021\n",
      "[92]\ttraining's auc: 0.913362\tvalid_1's auc: 0.85797\n",
      "[93]\ttraining's auc: 0.917838\tvalid_1's auc: 0.864714\n",
      "[94]\ttraining's auc: 0.919417\tvalid_1's auc: 0.864067\n",
      "[95]\ttraining's auc: 0.906878\tvalid_1's auc: 0.85131\n",
      "[96]\ttraining's auc: 0.905895\tvalid_1's auc: 0.85093\n",
      "[97]\ttraining's auc: 0.913533\tvalid_1's auc: 0.857835\n",
      "[98]\ttraining's auc: 0.907053\tvalid_1's auc: 0.855449\n",
      "[99]\ttraining's auc: 0.897158\tvalid_1's auc: 0.84695\n",
      "[100]\ttraining's auc: 0.912298\tvalid_1's auc: 0.863514\n",
      "[101]\ttraining's auc: 0.910031\tvalid_1's auc: 0.861158\n",
      "[102]\ttraining's auc: 0.908151\tvalid_1's auc: 0.861006\n",
      "[103]\ttraining's auc: 0.907383\tvalid_1's auc: 0.859539\n",
      "[104]\ttraining's auc: 0.907044\tvalid_1's auc: 0.858306\n",
      "[105]\ttraining's auc: 0.875806\tvalid_1's auc: 0.825686\n",
      "[106]\ttraining's auc: 0.895598\tvalid_1's auc: 0.852247\n",
      "[107]\ttraining's auc: 0.895877\tvalid_1's auc: 0.850338\n",
      "[108]\ttraining's auc: 0.907915\tvalid_1's auc: 0.863946\n",
      "[109]\ttraining's auc: 0.891537\tvalid_1's auc: 0.837619\n",
      "[110]\ttraining's auc: 0.878063\tvalid_1's auc: 0.828198\n",
      "[111]\ttraining's auc: 0.870004\tvalid_1's auc: 0.816284\n",
      "[112]\ttraining's auc: 0.881744\tvalid_1's auc: 0.829365\n",
      "[113]\ttraining's auc: 0.889653\tvalid_1's auc: 0.837651\n",
      "[114]\ttraining's auc: 0.891081\tvalid_1's auc: 0.839384\n",
      "[115]\ttraining's auc: 0.878003\tvalid_1's auc: 0.832091\n",
      "[116]\ttraining's auc: 0.87468\tvalid_1's auc: 0.833982\n",
      "[117]\ttraining's auc: 0.868961\tvalid_1's auc: 0.830704\n",
      "[118]\ttraining's auc: 0.881473\tvalid_1's auc: 0.843689\n",
      "[119]\ttraining's auc: 0.878872\tvalid_1's auc: 0.840808\n",
      "[120]\ttraining's auc: 0.875411\tvalid_1's auc: 0.839543\n",
      "[121]\ttraining's auc: 0.872973\tvalid_1's auc: 0.839793\n",
      "[122]\ttraining's auc: 0.879186\tvalid_1's auc: 0.834765\n",
      "[123]\ttraining's auc: 0.878677\tvalid_1's auc: 0.834363\n",
      "[124]\ttraining's auc: 0.875527\tvalid_1's auc: 0.830837\n",
      "[125]\ttraining's auc: 0.865349\tvalid_1's auc: 0.821407\n",
      "[126]\ttraining's auc: 0.86773\tvalid_1's auc: 0.828862\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.931302\tvalid_1's auc: 0.921739\n",
      "[1]\ttraining's auc: 0.706448\tvalid_1's auc: 0.722884\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.751781\tvalid_1's auc: 0.747227\n",
      "[3]\ttraining's auc: 0.761973\tvalid_1's auc: 0.763352\n",
      "[4]\ttraining's auc: 0.879879\tvalid_1's auc: 0.865484\n",
      "[5]\ttraining's auc: 0.902091\tvalid_1's auc: 0.893194\n",
      "[6]\ttraining's auc: 0.908495\tvalid_1's auc: 0.89693\n",
      "[7]\ttraining's auc: 0.913205\tvalid_1's auc: 0.89831\n",
      "[8]\ttraining's auc: 0.915843\tvalid_1's auc: 0.90117\n",
      "[9]\ttraining's auc: 0.91845\tvalid_1's auc: 0.900564\n",
      "[10]\ttraining's auc: 0.918996\tvalid_1's auc: 0.901923\n",
      "[11]\ttraining's auc: 0.920563\tvalid_1's auc: 0.902731\n",
      "[12]\ttraining's auc: 0.922887\tvalid_1's auc: 0.902986\n",
      "[13]\ttraining's auc: 0.922973\tvalid_1's auc: 0.902938\n",
      "[14]\ttraining's auc: 0.923332\tvalid_1's auc: 0.902052\n",
      "[15]\ttraining's auc: 0.923131\tvalid_1's auc: 0.90319\n",
      "[16]\ttraining's auc: 0.923177\tvalid_1's auc: 0.902071\n",
      "[17]\ttraining's auc: 0.924975\tvalid_1's auc: 0.903804\n",
      "[18]\ttraining's auc: 0.925676\tvalid_1's auc: 0.903804\n",
      "[19]\ttraining's auc: 0.926388\tvalid_1's auc: 0.903664\n",
      "[20]\ttraining's auc: 0.927297\tvalid_1's auc: 0.902203\n",
      "[21]\ttraining's auc: 0.927512\tvalid_1's auc: 0.900967\n",
      "[22]\ttraining's auc: 0.927157\tvalid_1's auc: 0.898754\n",
      "[23]\ttraining's auc: 0.92765\tvalid_1's auc: 0.898777\n",
      "[24]\ttraining's auc: 0.928892\tvalid_1's auc: 0.900055\n",
      "[25]\ttraining's auc: 0.928697\tvalid_1's auc: 0.897926\n",
      "[26]\ttraining's auc: 0.928902\tvalid_1's auc: 0.898852\n",
      "[27]\ttraining's auc: 0.930385\tvalid_1's auc: 0.899837\n",
      "[28]\ttraining's auc: 0.930789\tvalid_1's auc: 0.89782\n",
      "[29]\ttraining's auc: 0.930618\tvalid_1's auc: 0.896991\n",
      "[30]\ttraining's auc: 0.931109\tvalid_1's auc: 0.895758\n",
      "[31]\ttraining's auc: 0.931453\tvalid_1's auc: 0.896308\n",
      "[32]\ttraining's auc: 0.932181\tvalid_1's auc: 0.895481\n",
      "[33]\ttraining's auc: 0.933604\tvalid_1's auc: 0.894627\n",
      "[34]\ttraining's auc: 0.933927\tvalid_1's auc: 0.892216\n",
      "[35]\ttraining's auc: 0.933812\tvalid_1's auc: 0.893682\n",
      "[36]\ttraining's auc: 0.934112\tvalid_1's auc: 0.892342\n",
      "[37]\ttraining's auc: 0.933707\tvalid_1's auc: 0.893209\n",
      "[38]\ttraining's auc: 0.934423\tvalid_1's auc: 0.892704\n",
      "[39]\ttraining's auc: 0.933993\tvalid_1's auc: 0.890204\n",
      "[40]\ttraining's auc: 0.93429\tvalid_1's auc: 0.89073\n",
      "[41]\ttraining's auc: 0.933179\tvalid_1's auc: 0.890515\n",
      "[42]\ttraining's auc: 0.93272\tvalid_1's auc: 0.888123\n",
      "[43]\ttraining's auc: 0.933577\tvalid_1's auc: 0.889537\n",
      "[44]\ttraining's auc: 0.934132\tvalid_1's auc: 0.891334\n",
      "[45]\ttraining's auc: 0.934028\tvalid_1's auc: 0.891307\n",
      "[46]\ttraining's auc: 0.934635\tvalid_1's auc: 0.889624\n",
      "[47]\ttraining's auc: 0.934822\tvalid_1's auc: 0.887665\n",
      "[48]\ttraining's auc: 0.935465\tvalid_1's auc: 0.886586\n",
      "[49]\ttraining's auc: 0.936134\tvalid_1's auc: 0.886206\n",
      "[50]\ttraining's auc: 0.936026\tvalid_1's auc: 0.885022\n",
      "[51]\ttraining's auc: 0.935919\tvalid_1's auc: 0.885096\n",
      "[52]\ttraining's auc: 0.93609\tvalid_1's auc: 0.883082\n",
      "[53]\ttraining's auc: 0.936727\tvalid_1's auc: 0.882893\n",
      "[54]\ttraining's auc: 0.936614\tvalid_1's auc: 0.882995\n",
      "[55]\ttraining's auc: 0.936937\tvalid_1's auc: 0.883018\n",
      "[56]\ttraining's auc: 0.936756\tvalid_1's auc: 0.882353\n",
      "[57]\ttraining's auc: 0.932921\tvalid_1's auc: 0.876309\n",
      "[58]\ttraining's auc: 0.932657\tvalid_1's auc: 0.876567\n",
      "[59]\ttraining's auc: 0.933311\tvalid_1's auc: 0.878946\n",
      "[60]\ttraining's auc: 0.93387\tvalid_1's auc: 0.879986\n",
      "[61]\ttraining's auc: 0.933708\tvalid_1's auc: 0.88135\n",
      "[62]\ttraining's auc: 0.933802\tvalid_1's auc: 0.880301\n",
      "[63]\ttraining's auc: 0.935007\tvalid_1's auc: 0.882344\n",
      "[64]\ttraining's auc: 0.936078\tvalid_1's auc: 0.882379\n",
      "[65]\ttraining's auc: 0.935825\tvalid_1's auc: 0.882596\n",
      "[66]\ttraining's auc: 0.933783\tvalid_1's auc: 0.87981\n",
      "[67]\ttraining's auc: 0.933928\tvalid_1's auc: 0.878681\n",
      "[68]\ttraining's auc: 0.933907\tvalid_1's auc: 0.877341\n",
      "[69]\ttraining's auc: 0.934274\tvalid_1's auc: 0.877764\n",
      "[70]\ttraining's auc: 0.93495\tvalid_1's auc: 0.876075\n",
      "[71]\ttraining's auc: 0.93529\tvalid_1's auc: 0.87564\n",
      "[72]\ttraining's auc: 0.930865\tvalid_1's auc: 0.870154\n",
      "[73]\ttraining's auc: 0.932309\tvalid_1's auc: 0.871298\n",
      "[74]\ttraining's auc: 0.933515\tvalid_1's auc: 0.872583\n",
      "[75]\ttraining's auc: 0.931209\tvalid_1's auc: 0.868412\n",
      "[76]\ttraining's auc: 0.932364\tvalid_1's auc: 0.867731\n",
      "[77]\ttraining's auc: 0.932031\tvalid_1's auc: 0.867857\n",
      "[78]\ttraining's auc: 0.928976\tvalid_1's auc: 0.865164\n",
      "[79]\ttraining's auc: 0.930463\tvalid_1's auc: 0.866668\n",
      "[80]\ttraining's auc: 0.90202\tvalid_1's auc: 0.846761\n",
      "[81]\ttraining's auc: 0.919781\tvalid_1's auc: 0.863707\n",
      "[82]\ttraining's auc: 0.924843\tvalid_1's auc: 0.869056\n",
      "[83]\ttraining's auc: 0.925535\tvalid_1's auc: 0.868938\n",
      "[84]\ttraining's auc: 0.913868\tvalid_1's auc: 0.85553\n",
      "[85]\ttraining's auc: 0.916173\tvalid_1's auc: 0.858221\n",
      "[86]\ttraining's auc: 0.906903\tvalid_1's auc: 0.854832\n",
      "[87]\ttraining's auc: 0.903822\tvalid_1's auc: 0.854826\n",
      "[88]\ttraining's auc: 0.917331\tvalid_1's auc: 0.866278\n",
      "[89]\ttraining's auc: 0.912498\tvalid_1's auc: 0.859758\n",
      "[90]\ttraining's auc: 0.911765\tvalid_1's auc: 0.860047\n",
      "[91]\ttraining's auc: 0.91043\tvalid_1's auc: 0.857827\n",
      "[92]\ttraining's auc: 0.911871\tvalid_1's auc: 0.861631\n",
      "[93]\ttraining's auc: 0.916555\tvalid_1's auc: 0.868908\n",
      "[94]\ttraining's auc: 0.904043\tvalid_1's auc: 0.857756\n",
      "[95]\ttraining's auc: 0.911372\tvalid_1's auc: 0.865388\n",
      "[96]\ttraining's auc: 0.916332\tvalid_1's auc: 0.867429\n",
      "[97]\ttraining's auc: 0.913442\tvalid_1's auc: 0.859524\n",
      "[98]\ttraining's auc: 0.914432\tvalid_1's auc: 0.861242\n",
      "[99]\ttraining's auc: 0.914907\tvalid_1's auc: 0.862579\n",
      "[100]\ttraining's auc: 0.914305\tvalid_1's auc: 0.862008\n",
      "[101]\ttraining's auc: 0.914074\tvalid_1's auc: 0.863084\n",
      "[102]\ttraining's auc: 0.914366\tvalid_1's auc: 0.862439\n",
      "[103]\ttraining's auc: 0.914625\tvalid_1's auc: 0.867393\n",
      "[104]\ttraining's auc: 0.913986\tvalid_1's auc: 0.866197\n",
      "[105]\ttraining's auc: 0.912427\tvalid_1's auc: 0.862927\n",
      "[106]\ttraining's auc: 0.896092\tvalid_1's auc: 0.848452\n",
      "[107]\ttraining's auc: 0.911858\tvalid_1's auc: 0.856363\n",
      "[108]\ttraining's auc: 0.909041\tvalid_1's auc: 0.854391\n",
      "[109]\ttraining's auc: 0.909999\tvalid_1's auc: 0.856184\n",
      "[110]\ttraining's auc: 0.91265\tvalid_1's auc: 0.860496\n",
      "[111]\ttraining's auc: 0.907296\tvalid_1's auc: 0.855748\n",
      "[112]\ttraining's auc: 0.910788\tvalid_1's auc: 0.860386\n",
      "[113]\ttraining's auc: 0.905887\tvalid_1's auc: 0.853768\n",
      "[114]\ttraining's auc: 0.902419\tvalid_1's auc: 0.848656\n",
      "[115]\ttraining's auc: 0.90152\tvalid_1's auc: 0.845138\n",
      "[116]\ttraining's auc: 0.895201\tvalid_1's auc: 0.837846\n",
      "[117]\ttraining's auc: 0.90128\tvalid_1's auc: 0.843802\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.924975\tvalid_1's auc: 0.903804\n",
      "[1]\ttraining's auc: 0.860398\tvalid_1's auc: 0.865231\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.886343\tvalid_1's auc: 0.889624\n",
      "[3]\ttraining's auc: 0.894344\tvalid_1's auc: 0.891435\n",
      "[4]\ttraining's auc: 0.897278\tvalid_1's auc: 0.889401\n",
      "[5]\ttraining's auc: 0.901563\tvalid_1's auc: 0.895848\n",
      "[6]\ttraining's auc: 0.905496\tvalid_1's auc: 0.899747\n",
      "[7]\ttraining's auc: 0.909513\tvalid_1's auc: 0.906218\n",
      "[8]\ttraining's auc: 0.912055\tvalid_1's auc: 0.909189\n",
      "[9]\ttraining's auc: 0.91457\tvalid_1's auc: 0.90927\n",
      "[10]\ttraining's auc: 0.91542\tvalid_1's auc: 0.909227\n",
      "[11]\ttraining's auc: 0.919609\tvalid_1's auc: 0.916144\n",
      "[12]\ttraining's auc: 0.921453\tvalid_1's auc: 0.916969\n",
      "[13]\ttraining's auc: 0.922929\tvalid_1's auc: 0.917641\n",
      "[14]\ttraining's auc: 0.925222\tvalid_1's auc: 0.918725\n",
      "[15]\ttraining's auc: 0.925599\tvalid_1's auc: 0.920266\n",
      "[16]\ttraining's auc: 0.926063\tvalid_1's auc: 0.919792\n",
      "[17]\ttraining's auc: 0.926662\tvalid_1's auc: 0.918645\n",
      "[18]\ttraining's auc: 0.927472\tvalid_1's auc: 0.918292\n",
      "[19]\ttraining's auc: 0.928557\tvalid_1's auc: 0.918769\n",
      "[20]\ttraining's auc: 0.928879\tvalid_1's auc: 0.91939\n",
      "[21]\ttraining's auc: 0.929222\tvalid_1's auc: 0.919127\n",
      "[22]\ttraining's auc: 0.929946\tvalid_1's auc: 0.91998\n",
      "[23]\ttraining's auc: 0.929179\tvalid_1's auc: 0.918981\n",
      "[24]\ttraining's auc: 0.929042\tvalid_1's auc: 0.917821\n",
      "[25]\ttraining's auc: 0.929654\tvalid_1's auc: 0.917654\n",
      "[26]\ttraining's auc: 0.929832\tvalid_1's auc: 0.916509\n",
      "[27]\ttraining's auc: 0.929546\tvalid_1's auc: 0.913265\n",
      "[28]\ttraining's auc: 0.930158\tvalid_1's auc: 0.912742\n",
      "[29]\ttraining's auc: 0.930451\tvalid_1's auc: 0.913003\n",
      "[30]\ttraining's auc: 0.92922\tvalid_1's auc: 0.911364\n",
      "[31]\ttraining's auc: 0.930217\tvalid_1's auc: 0.912428\n",
      "[32]\ttraining's auc: 0.929515\tvalid_1's auc: 0.912901\n",
      "[33]\ttraining's auc: 0.929882\tvalid_1's auc: 0.911288\n",
      "[34]\ttraining's auc: 0.929569\tvalid_1's auc: 0.910856\n",
      "[35]\ttraining's auc: 0.929184\tvalid_1's auc: 0.911974\n",
      "[36]\ttraining's auc: 0.929869\tvalid_1's auc: 0.911068\n",
      "[37]\ttraining's auc: 0.931289\tvalid_1's auc: 0.913023\n",
      "[38]\ttraining's auc: 0.930827\tvalid_1's auc: 0.912245\n",
      "[39]\ttraining's auc: 0.932243\tvalid_1's auc: 0.912767\n",
      "[40]\ttraining's auc: 0.932125\tvalid_1's auc: 0.910638\n",
      "[41]\ttraining's auc: 0.93248\tvalid_1's auc: 0.908841\n",
      "[42]\ttraining's auc: 0.932532\tvalid_1's auc: 0.90881\n",
      "[43]\ttraining's auc: 0.933039\tvalid_1's auc: 0.907911\n",
      "[44]\ttraining's auc: 0.933207\tvalid_1's auc: 0.907426\n",
      "[45]\ttraining's auc: 0.927579\tvalid_1's auc: 0.898716\n",
      "[46]\ttraining's auc: 0.92845\tvalid_1's auc: 0.896092\n",
      "[47]\ttraining's auc: 0.929579\tvalid_1's auc: 0.89821\n",
      "[48]\ttraining's auc: 0.930038\tvalid_1's auc: 0.897965\n",
      "[49]\ttraining's auc: 0.930938\tvalid_1's auc: 0.897364\n",
      "[50]\ttraining's auc: 0.931734\tvalid_1's auc: 0.898511\n",
      "[51]\ttraining's auc: 0.931425\tvalid_1's auc: 0.89494\n",
      "[52]\ttraining's auc: 0.931798\tvalid_1's auc: 0.895443\n",
      "[53]\ttraining's auc: 0.931688\tvalid_1's auc: 0.895019\n",
      "[54]\ttraining's auc: 0.932243\tvalid_1's auc: 0.896453\n",
      "[55]\ttraining's auc: 0.932795\tvalid_1's auc: 0.895441\n",
      "[56]\ttraining's auc: 0.933577\tvalid_1's auc: 0.896966\n",
      "[57]\ttraining's auc: 0.934309\tvalid_1's auc: 0.898419\n",
      "[58]\ttraining's auc: 0.933617\tvalid_1's auc: 0.895512\n",
      "[59]\ttraining's auc: 0.930563\tvalid_1's auc: 0.892083\n",
      "[60]\ttraining's auc: 0.93216\tvalid_1's auc: 0.892167\n",
      "[61]\ttraining's auc: 0.929512\tvalid_1's auc: 0.890533\n",
      "[62]\ttraining's auc: 0.930608\tvalid_1's auc: 0.890709\n",
      "[63]\ttraining's auc: 0.930876\tvalid_1's auc: 0.890381\n",
      "[64]\ttraining's auc: 0.931969\tvalid_1's auc: 0.892854\n",
      "[65]\ttraining's auc: 0.931928\tvalid_1's auc: 0.894083\n",
      "[66]\ttraining's auc: 0.934223\tvalid_1's auc: 0.895763\n",
      "[67]\ttraining's auc: 0.934177\tvalid_1's auc: 0.897528\n",
      "[68]\ttraining's auc: 0.934577\tvalid_1's auc: 0.899432\n",
      "[69]\ttraining's auc: 0.934183\tvalid_1's auc: 0.899034\n",
      "[70]\ttraining's auc: 0.933527\tvalid_1's auc: 0.898771\n",
      "[71]\ttraining's auc: 0.933924\tvalid_1's auc: 0.900009\n",
      "[72]\ttraining's auc: 0.928923\tvalid_1's auc: 0.892849\n",
      "[73]\ttraining's auc: 0.929814\tvalid_1's auc: 0.891955\n",
      "[74]\ttraining's auc: 0.929345\tvalid_1's auc: 0.892061\n",
      "[75]\ttraining's auc: 0.928503\tvalid_1's auc: 0.889361\n",
      "[76]\ttraining's auc: 0.922237\tvalid_1's auc: 0.883401\n",
      "[77]\ttraining's auc: 0.923811\tvalid_1's auc: 0.8848\n",
      "[78]\ttraining's auc: 0.925935\tvalid_1's auc: 0.886817\n",
      "[79]\ttraining's auc: 0.927586\tvalid_1's auc: 0.887675\n",
      "[80]\ttraining's auc: 0.919303\tvalid_1's auc: 0.879026\n",
      "[81]\ttraining's auc: 0.911416\tvalid_1's auc: 0.871674\n",
      "[82]\ttraining's auc: 0.916586\tvalid_1's auc: 0.878511\n",
      "[83]\ttraining's auc: 0.921528\tvalid_1's auc: 0.881572\n",
      "[84]\ttraining's auc: 0.92163\tvalid_1's auc: 0.88303\n",
      "[85]\ttraining's auc: 0.917953\tvalid_1's auc: 0.8766\n",
      "[86]\ttraining's auc: 0.919372\tvalid_1's auc: 0.876532\n",
      "[87]\ttraining's auc: 0.919392\tvalid_1's auc: 0.875376\n",
      "[88]\ttraining's auc: 0.915095\tvalid_1's auc: 0.871878\n",
      "[89]\ttraining's auc: 0.915243\tvalid_1's auc: 0.870057\n",
      "[90]\ttraining's auc: 0.924589\tvalid_1's auc: 0.881108\n",
      "[91]\ttraining's auc: 0.922874\tvalid_1's auc: 0.877144\n",
      "[92]\ttraining's auc: 0.92333\tvalid_1's auc: 0.877364\n",
      "[93]\ttraining's auc: 0.923682\tvalid_1's auc: 0.875986\n",
      "[94]\ttraining's auc: 0.913726\tvalid_1's auc: 0.870182\n",
      "[95]\ttraining's auc: 0.917287\tvalid_1's auc: 0.874753\n",
      "[96]\ttraining's auc: 0.905592\tvalid_1's auc: 0.853009\n",
      "[97]\ttraining's auc: 0.921101\tvalid_1's auc: 0.872487\n",
      "[98]\ttraining's auc: 0.919629\tvalid_1's auc: 0.874785\n",
      "[99]\ttraining's auc: 0.918291\tvalid_1's auc: 0.872524\n",
      "[100]\ttraining's auc: 0.919471\tvalid_1's auc: 0.874266\n",
      "[101]\ttraining's auc: 0.917503\tvalid_1's auc: 0.870254\n",
      "[102]\ttraining's auc: 0.915319\tvalid_1's auc: 0.864063\n",
      "[103]\ttraining's auc: 0.890505\tvalid_1's auc: 0.838338\n",
      "[104]\ttraining's auc: 0.832456\tvalid_1's auc: 0.779766\n",
      "[105]\ttraining's auc: 0.907384\tvalid_1's auc: 0.865325\n",
      "[106]\ttraining's auc: 0.908058\tvalid_1's auc: 0.865839\n",
      "[107]\ttraining's auc: 0.905602\tvalid_1's auc: 0.861278\n",
      "[108]\ttraining's auc: 0.894925\tvalid_1's auc: 0.851293\n",
      "[109]\ttraining's auc: 0.898794\tvalid_1's auc: 0.856972\n",
      "[110]\ttraining's auc: 0.895823\tvalid_1's auc: 0.856614\n",
      "[111]\ttraining's auc: 0.899647\tvalid_1's auc: 0.858023\n",
      "[112]\ttraining's auc: 0.891732\tvalid_1's auc: 0.848438\n",
      "[113]\ttraining's auc: 0.885519\tvalid_1's auc: 0.839595\n",
      "[114]\ttraining's auc: 0.884518\tvalid_1's auc: 0.836985\n",
      "[115]\ttraining's auc: 0.881756\tvalid_1's auc: 0.837801\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.925599\tvalid_1's auc: 0.920266\n",
      "[1]\ttraining's auc: 0.847344\tvalid_1's auc: 0.840225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.887445\tvalid_1's auc: 0.877242\n",
      "[3]\ttraining's auc: 0.898338\tvalid_1's auc: 0.893687\n",
      "[4]\ttraining's auc: 0.906002\tvalid_1's auc: 0.90547\n",
      "[5]\ttraining's auc: 0.909083\tvalid_1's auc: 0.909006\n",
      "[6]\ttraining's auc: 0.910554\tvalid_1's auc: 0.909881\n",
      "[7]\ttraining's auc: 0.913223\tvalid_1's auc: 0.912632\n",
      "[8]\ttraining's auc: 0.914168\tvalid_1's auc: 0.913962\n",
      "[9]\ttraining's auc: 0.915583\tvalid_1's auc: 0.914576\n",
      "[10]\ttraining's auc: 0.918161\tvalid_1's auc: 0.916758\n",
      "[11]\ttraining's auc: 0.919643\tvalid_1's auc: 0.920028\n",
      "[12]\ttraining's auc: 0.919742\tvalid_1's auc: 0.920334\n",
      "[13]\ttraining's auc: 0.920421\tvalid_1's auc: 0.916713\n",
      "[14]\ttraining's auc: 0.921998\tvalid_1's auc: 0.916818\n",
      "[15]\ttraining's auc: 0.92271\tvalid_1's auc: 0.916121\n",
      "[16]\ttraining's auc: 0.923076\tvalid_1's auc: 0.915952\n",
      "[17]\ttraining's auc: 0.924254\tvalid_1's auc: 0.91639\n",
      "[18]\ttraining's auc: 0.924841\tvalid_1's auc: 0.917462\n",
      "[19]\ttraining's auc: 0.926034\tvalid_1's auc: 0.918533\n",
      "[20]\ttraining's auc: 0.926768\tvalid_1's auc: 0.91796\n",
      "[21]\ttraining's auc: 0.926957\tvalid_1's auc: 0.917759\n",
      "[22]\ttraining's auc: 0.928307\tvalid_1's auc: 0.918388\n",
      "[23]\ttraining's auc: 0.928751\tvalid_1's auc: 0.917904\n",
      "[24]\ttraining's auc: 0.929196\tvalid_1's auc: 0.914956\n",
      "[25]\ttraining's auc: 0.929495\tvalid_1's auc: 0.915864\n",
      "[26]\ttraining's auc: 0.929485\tvalid_1's auc: 0.915186\n",
      "[27]\ttraining's auc: 0.929771\tvalid_1's auc: 0.913996\n",
      "[28]\ttraining's auc: 0.930121\tvalid_1's auc: 0.916279\n",
      "[29]\ttraining's auc: 0.930447\tvalid_1's auc: 0.916528\n",
      "[30]\ttraining's auc: 0.930275\tvalid_1's auc: 0.916741\n",
      "[31]\ttraining's auc: 0.929942\tvalid_1's auc: 0.916049\n",
      "[32]\ttraining's auc: 0.930295\tvalid_1's auc: 0.914512\n",
      "[33]\ttraining's auc: 0.92988\tvalid_1's auc: 0.913065\n",
      "[34]\ttraining's auc: 0.93004\tvalid_1's auc: 0.912285\n",
      "[35]\ttraining's auc: 0.930067\tvalid_1's auc: 0.911908\n",
      "[36]\ttraining's auc: 0.930708\tvalid_1's auc: 0.913294\n",
      "[37]\ttraining's auc: 0.9307\tvalid_1's auc: 0.913718\n",
      "[38]\ttraining's auc: 0.931257\tvalid_1's auc: 0.911634\n",
      "[39]\ttraining's auc: 0.9311\tvalid_1's auc: 0.910534\n",
      "[40]\ttraining's auc: 0.930767\tvalid_1's auc: 0.910388\n",
      "[41]\ttraining's auc: 0.931881\tvalid_1's auc: 0.911106\n",
      "[42]\ttraining's auc: 0.932003\tvalid_1's auc: 0.912166\n",
      "[43]\ttraining's auc: 0.932262\tvalid_1's auc: 0.911513\n",
      "[44]\ttraining's auc: 0.933234\tvalid_1's auc: 0.912495\n",
      "[45]\ttraining's auc: 0.933811\tvalid_1's auc: 0.912688\n",
      "[46]\ttraining's auc: 0.933649\tvalid_1's auc: 0.912747\n",
      "[47]\ttraining's auc: 0.933378\tvalid_1's auc: 0.911018\n",
      "[48]\ttraining's auc: 0.933598\tvalid_1's auc: 0.91007\n",
      "[49]\ttraining's auc: 0.933659\tvalid_1's auc: 0.909333\n",
      "[50]\ttraining's auc: 0.933271\tvalid_1's auc: 0.906902\n",
      "[51]\ttraining's auc: 0.934339\tvalid_1's auc: 0.907481\n",
      "[52]\ttraining's auc: 0.935601\tvalid_1's auc: 0.909973\n",
      "[53]\ttraining's auc: 0.935803\tvalid_1's auc: 0.908593\n",
      "[54]\ttraining's auc: 0.935593\tvalid_1's auc: 0.908477\n",
      "[55]\ttraining's auc: 0.935449\tvalid_1's auc: 0.909135\n",
      "[56]\ttraining's auc: 0.935563\tvalid_1's auc: 0.908368\n",
      "[57]\ttraining's auc: 0.935679\tvalid_1's auc: 0.90812\n",
      "[58]\ttraining's auc: 0.936191\tvalid_1's auc: 0.909261\n",
      "[59]\ttraining's auc: 0.935624\tvalid_1's auc: 0.908255\n",
      "[60]\ttraining's auc: 0.935385\tvalid_1's auc: 0.906197\n",
      "[61]\ttraining's auc: 0.935651\tvalid_1's auc: 0.903858\n",
      "[62]\ttraining's auc: 0.935956\tvalid_1's auc: 0.904713\n",
      "[63]\ttraining's auc: 0.935412\tvalid_1's auc: 0.902348\n",
      "[64]\ttraining's auc: 0.934823\tvalid_1's auc: 0.900472\n",
      "[65]\ttraining's auc: 0.93547\tvalid_1's auc: 0.900732\n",
      "[66]\ttraining's auc: 0.935667\tvalid_1's auc: 0.899421\n",
      "[67]\ttraining's auc: 0.936375\tvalid_1's auc: 0.901761\n",
      "[68]\ttraining's auc: 0.936817\tvalid_1's auc: 0.901833\n",
      "[69]\ttraining's auc: 0.937393\tvalid_1's auc: 0.900359\n",
      "[70]\ttraining's auc: 0.937055\tvalid_1's auc: 0.900531\n",
      "[71]\ttraining's auc: 0.936674\tvalid_1's auc: 0.902225\n",
      "[72]\ttraining's auc: 0.937289\tvalid_1's auc: 0.903423\n",
      "[73]\ttraining's auc: 0.937279\tvalid_1's auc: 0.900202\n",
      "[74]\ttraining's auc: 0.93742\tvalid_1's auc: 0.901371\n",
      "[75]\ttraining's auc: 0.937797\tvalid_1's auc: 0.9013\n",
      "[76]\ttraining's auc: 0.935169\tvalid_1's auc: 0.901894\n",
      "[77]\ttraining's auc: 0.93501\tvalid_1's auc: 0.900221\n",
      "[78]\ttraining's auc: 0.935109\tvalid_1's auc: 0.901474\n",
      "[79]\ttraining's auc: 0.934459\tvalid_1's auc: 0.90287\n",
      "[80]\ttraining's auc: 0.934391\tvalid_1's auc: 0.903236\n",
      "[81]\ttraining's auc: 0.929845\tvalid_1's auc: 0.895917\n",
      "[82]\ttraining's auc: 0.931261\tvalid_1's auc: 0.897239\n",
      "[83]\ttraining's auc: 0.932538\tvalid_1's auc: 0.898791\n",
      "[84]\ttraining's auc: 0.933491\tvalid_1's auc: 0.900298\n",
      "[85]\ttraining's auc: 0.934518\tvalid_1's auc: 0.899321\n",
      "[86]\ttraining's auc: 0.935197\tvalid_1's auc: 0.901222\n",
      "[87]\ttraining's auc: 0.934235\tvalid_1's auc: 0.900003\n",
      "[88]\ttraining's auc: 0.919744\tvalid_1's auc: 0.879607\n",
      "[89]\ttraining's auc: 0.920061\tvalid_1's auc: 0.880556\n",
      "[90]\ttraining's auc: 0.91222\tvalid_1's auc: 0.872129\n",
      "[91]\ttraining's auc: 0.912444\tvalid_1's auc: 0.870885\n",
      "[92]\ttraining's auc: 0.917171\tvalid_1's auc: 0.882747\n",
      "[93]\ttraining's auc: 0.906067\tvalid_1's auc: 0.869391\n",
      "[94]\ttraining's auc: 0.914022\tvalid_1's auc: 0.874892\n",
      "[95]\ttraining's auc: 0.917876\tvalid_1's auc: 0.880181\n",
      "[96]\ttraining's auc: 0.919868\tvalid_1's auc: 0.875869\n",
      "[97]\ttraining's auc: 0.922794\tvalid_1's auc: 0.881264\n",
      "[98]\ttraining's auc: 0.919694\tvalid_1's auc: 0.877777\n",
      "[99]\ttraining's auc: 0.911188\tvalid_1's auc: 0.86417\n",
      "[100]\ttraining's auc: 0.916709\tvalid_1's auc: 0.879157\n",
      "[101]\ttraining's auc: 0.909979\tvalid_1's auc: 0.868843\n",
      "[102]\ttraining's auc: 0.909726\tvalid_1's auc: 0.867876\n",
      "[103]\ttraining's auc: 0.913618\tvalid_1's auc: 0.881154\n",
      "[104]\ttraining's auc: 0.913254\tvalid_1's auc: 0.88395\n",
      "[105]\ttraining's auc: 0.913389\tvalid_1's auc: 0.88475\n",
      "[106]\ttraining's auc: 0.902877\tvalid_1's auc: 0.878183\n",
      "[107]\ttraining's auc: 0.900931\tvalid_1's auc: 0.876278\n",
      "[108]\ttraining's auc: 0.893914\tvalid_1's auc: 0.862228\n",
      "[109]\ttraining's auc: 0.896028\tvalid_1's auc: 0.867854\n",
      "[110]\ttraining's auc: 0.892081\tvalid_1's auc: 0.868003\n",
      "[111]\ttraining's auc: 0.889373\tvalid_1's auc: 0.86979\n",
      "[112]\ttraining's auc: 0.896445\tvalid_1's auc: 0.87664\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.919742\tvalid_1's auc: 0.920334\n",
      "[1]\ttraining's auc: 0.715675\tvalid_1's auc: 0.685388\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.865896\tvalid_1's auc: 0.860484\n",
      "[3]\ttraining's auc: 0.889966\tvalid_1's auc: 0.893425\n",
      "[4]\ttraining's auc: 0.897145\tvalid_1's auc: 0.904293\n",
      "[5]\ttraining's auc: 0.897086\tvalid_1's auc: 0.899848\n",
      "[6]\ttraining's auc: 0.896673\tvalid_1's auc: 0.898411\n",
      "[7]\ttraining's auc: 0.903812\tvalid_1's auc: 0.90443\n",
      "[8]\ttraining's auc: 0.908139\tvalid_1's auc: 0.909039\n",
      "[9]\ttraining's auc: 0.911983\tvalid_1's auc: 0.911349\n",
      "[10]\ttraining's auc: 0.913351\tvalid_1's auc: 0.913484\n",
      "[11]\ttraining's auc: 0.915523\tvalid_1's auc: 0.91551\n",
      "[12]\ttraining's auc: 0.916534\tvalid_1's auc: 0.916611\n",
      "[13]\ttraining's auc: 0.917459\tvalid_1's auc: 0.916707\n",
      "[14]\ttraining's auc: 0.917827\tvalid_1's auc: 0.917778\n",
      "[15]\ttraining's auc: 0.919892\tvalid_1's auc: 0.919599\n",
      "[16]\ttraining's auc: 0.92012\tvalid_1's auc: 0.919359\n",
      "[17]\ttraining's auc: 0.921396\tvalid_1's auc: 0.918264\n",
      "[18]\ttraining's auc: 0.922307\tvalid_1's auc: 0.917177\n",
      "[19]\ttraining's auc: 0.923752\tvalid_1's auc: 0.916605\n",
      "[20]\ttraining's auc: 0.925146\tvalid_1's auc: 0.916973\n",
      "[21]\ttraining's auc: 0.925781\tvalid_1's auc: 0.91668\n",
      "[22]\ttraining's auc: 0.926787\tvalid_1's auc: 0.914565\n",
      "[23]\ttraining's auc: 0.926736\tvalid_1's auc: 0.913872\n",
      "[24]\ttraining's auc: 0.926222\tvalid_1's auc: 0.913223\n",
      "[25]\ttraining's auc: 0.92614\tvalid_1's auc: 0.912271\n",
      "[26]\ttraining's auc: 0.927321\tvalid_1's auc: 0.913434\n",
      "[27]\ttraining's auc: 0.927844\tvalid_1's auc: 0.912534\n",
      "[28]\ttraining's auc: 0.92788\tvalid_1's auc: 0.909669\n",
      "[29]\ttraining's auc: 0.928496\tvalid_1's auc: 0.910063\n",
      "[30]\ttraining's auc: 0.929432\tvalid_1's auc: 0.90896\n",
      "[31]\ttraining's auc: 0.930555\tvalid_1's auc: 0.910291\n",
      "[32]\ttraining's auc: 0.931025\tvalid_1's auc: 0.911368\n",
      "[33]\ttraining's auc: 0.931624\tvalid_1's auc: 0.911413\n",
      "[34]\ttraining's auc: 0.931605\tvalid_1's auc: 0.912227\n",
      "[35]\ttraining's auc: 0.931654\tvalid_1's auc: 0.9121\n",
      "[36]\ttraining's auc: 0.93171\tvalid_1's auc: 0.912713\n",
      "[37]\ttraining's auc: 0.931987\tvalid_1's auc: 0.912098\n",
      "[38]\ttraining's auc: 0.931744\tvalid_1's auc: 0.9098\n",
      "[39]\ttraining's auc: 0.931585\tvalid_1's auc: 0.90878\n",
      "[40]\ttraining's auc: 0.931667\tvalid_1's auc: 0.909412\n",
      "[41]\ttraining's auc: 0.930938\tvalid_1's auc: 0.908426\n",
      "[42]\ttraining's auc: 0.93176\tvalid_1's auc: 0.908176\n",
      "[43]\ttraining's auc: 0.93134\tvalid_1's auc: 0.907673\n",
      "[44]\ttraining's auc: 0.932023\tvalid_1's auc: 0.90528\n",
      "[45]\ttraining's auc: 0.932268\tvalid_1's auc: 0.903092\n",
      "[46]\ttraining's auc: 0.931707\tvalid_1's auc: 0.902989\n",
      "[47]\ttraining's auc: 0.931465\tvalid_1's auc: 0.899506\n",
      "[48]\ttraining's auc: 0.932507\tvalid_1's auc: 0.899889\n",
      "[49]\ttraining's auc: 0.933522\tvalid_1's auc: 0.901124\n",
      "[50]\ttraining's auc: 0.932603\tvalid_1's auc: 0.89751\n",
      "[51]\ttraining's auc: 0.931091\tvalid_1's auc: 0.895854\n",
      "[52]\ttraining's auc: 0.931515\tvalid_1's auc: 0.897176\n",
      "[53]\ttraining's auc: 0.931263\tvalid_1's auc: 0.895946\n",
      "[54]\ttraining's auc: 0.932249\tvalid_1's auc: 0.896684\n",
      "[55]\ttraining's auc: 0.932521\tvalid_1's auc: 0.89579\n",
      "[56]\ttraining's auc: 0.933118\tvalid_1's auc: 0.897423\n",
      "[57]\ttraining's auc: 0.933759\tvalid_1's auc: 0.899509\n",
      "[58]\ttraining's auc: 0.933154\tvalid_1's auc: 0.89891\n",
      "[59]\ttraining's auc: 0.933247\tvalid_1's auc: 0.899683\n",
      "[60]\ttraining's auc: 0.933427\tvalid_1's auc: 0.897481\n",
      "[61]\ttraining's auc: 0.933706\tvalid_1's auc: 0.897331\n",
      "[62]\ttraining's auc: 0.934534\tvalid_1's auc: 0.898343\n",
      "[63]\ttraining's auc: 0.934689\tvalid_1's auc: 0.899182\n",
      "[64]\ttraining's auc: 0.93482\tvalid_1's auc: 0.897564\n",
      "[65]\ttraining's auc: 0.934763\tvalid_1's auc: 0.896032\n",
      "[66]\ttraining's auc: 0.933435\tvalid_1's auc: 0.894865\n",
      "[67]\ttraining's auc: 0.933479\tvalid_1's auc: 0.89515\n",
      "[68]\ttraining's auc: 0.933911\tvalid_1's auc: 0.895016\n",
      "[69]\ttraining's auc: 0.934963\tvalid_1's auc: 0.895348\n",
      "[70]\ttraining's auc: 0.934687\tvalid_1's auc: 0.894163\n",
      "[71]\ttraining's auc: 0.934641\tvalid_1's auc: 0.892407\n",
      "[72]\ttraining's auc: 0.934028\tvalid_1's auc: 0.891877\n",
      "[73]\ttraining's auc: 0.933878\tvalid_1's auc: 0.890614\n",
      "[74]\ttraining's auc: 0.934569\tvalid_1's auc: 0.888512\n",
      "[75]\ttraining's auc: 0.933503\tvalid_1's auc: 0.887629\n",
      "[76]\ttraining's auc: 0.933729\tvalid_1's auc: 0.889242\n",
      "[77]\ttraining's auc: 0.933631\tvalid_1's auc: 0.888864\n",
      "[78]\ttraining's auc: 0.934079\tvalid_1's auc: 0.891003\n",
      "[79]\ttraining's auc: 0.932958\tvalid_1's auc: 0.88732\n",
      "[80]\ttraining's auc: 0.933652\tvalid_1's auc: 0.88884\n",
      "[81]\ttraining's auc: 0.933879\tvalid_1's auc: 0.887473\n",
      "[82]\ttraining's auc: 0.934434\tvalid_1's auc: 0.889723\n",
      "[83]\ttraining's auc: 0.934392\tvalid_1's auc: 0.890504\n",
      "[84]\ttraining's auc: 0.924551\tvalid_1's auc: 0.874145\n",
      "[85]\ttraining's auc: 0.9265\tvalid_1's auc: 0.879774\n",
      "[86]\ttraining's auc: 0.922084\tvalid_1's auc: 0.871367\n",
      "[87]\ttraining's auc: 0.924176\tvalid_1's auc: 0.874661\n",
      "[88]\ttraining's auc: 0.923717\tvalid_1's auc: 0.877958\n",
      "[89]\ttraining's auc: 0.925228\tvalid_1's auc: 0.879316\n",
      "[90]\ttraining's auc: 0.92526\tvalid_1's auc: 0.881491\n",
      "[91]\ttraining's auc: 0.915483\tvalid_1's auc: 0.875627\n",
      "[92]\ttraining's auc: 0.913478\tvalid_1's auc: 0.867277\n",
      "[93]\ttraining's auc: 0.911894\tvalid_1's auc: 0.86586\n",
      "[94]\ttraining's auc: 0.900627\tvalid_1's auc: 0.854103\n",
      "[95]\ttraining's auc: 0.899707\tvalid_1's auc: 0.854848\n",
      "[96]\ttraining's auc: 0.904378\tvalid_1's auc: 0.862069\n",
      "[97]\ttraining's auc: 0.902801\tvalid_1's auc: 0.857\n",
      "[98]\ttraining's auc: 0.903578\tvalid_1's auc: 0.859993\n",
      "[99]\ttraining's auc: 0.889974\tvalid_1's auc: 0.851626\n",
      "[100]\ttraining's auc: 0.884564\tvalid_1's auc: 0.85219\n",
      "[101]\ttraining's auc: 0.880345\tvalid_1's auc: 0.849165\n",
      "[102]\ttraining's auc: 0.87469\tvalid_1's auc: 0.844914\n",
      "[103]\ttraining's auc: 0.880845\tvalid_1's auc: 0.846377\n",
      "[104]\ttraining's auc: 0.878116\tvalid_1's auc: 0.842854\n",
      "[105]\ttraining's auc: 0.889444\tvalid_1's auc: 0.859496\n",
      "[106]\ttraining's auc: 0.875702\tvalid_1's auc: 0.844361\n",
      "[107]\ttraining's auc: 0.883469\tvalid_1's auc: 0.851319\n",
      "[108]\ttraining's auc: 0.887717\tvalid_1's auc: 0.861775\n",
      "[109]\ttraining's auc: 0.88829\tvalid_1's auc: 0.865706\n",
      "[110]\ttraining's auc: 0.888243\tvalid_1's auc: 0.867016\n",
      "[111]\ttraining's auc: 0.885654\tvalid_1's auc: 0.8671\n",
      "[112]\ttraining's auc: 0.882946\tvalid_1's auc: 0.86145\n",
      "[113]\ttraining's auc: 0.873666\tvalid_1's auc: 0.846706\n",
      "[114]\ttraining's auc: 0.876559\tvalid_1's auc: 0.850498\n",
      "[115]\ttraining's auc: 0.877014\tvalid_1's auc: 0.857049\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.919892\tvalid_1's auc: 0.919599\n",
      "[1]\ttraining's auc: 0.863793\tvalid_1's auc: 0.828057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.89139\tvalid_1's auc: 0.868058\n",
      "[3]\ttraining's auc: 0.899715\tvalid_1's auc: 0.875827\n",
      "[4]\ttraining's auc: 0.904085\tvalid_1's auc: 0.876062\n",
      "[5]\ttraining's auc: 0.907674\tvalid_1's auc: 0.885041\n",
      "[6]\ttraining's auc: 0.910164\tvalid_1's auc: 0.883101\n",
      "[7]\ttraining's auc: 0.913795\tvalid_1's auc: 0.885399\n",
      "[8]\ttraining's auc: 0.914568\tvalid_1's auc: 0.89138\n",
      "[9]\ttraining's auc: 0.916183\tvalid_1's auc: 0.893536\n",
      "[10]\ttraining's auc: 0.919316\tvalid_1's auc: 0.90056\n",
      "[11]\ttraining's auc: 0.92029\tvalid_1's auc: 0.899927\n",
      "[12]\ttraining's auc: 0.92114\tvalid_1's auc: 0.900087\n",
      "[13]\ttraining's auc: 0.922029\tvalid_1's auc: 0.89983\n",
      "[14]\ttraining's auc: 0.922529\tvalid_1's auc: 0.899692\n",
      "[15]\ttraining's auc: 0.922433\tvalid_1's auc: 0.897247\n",
      "[16]\ttraining's auc: 0.923047\tvalid_1's auc: 0.898804\n",
      "[17]\ttraining's auc: 0.923381\tvalid_1's auc: 0.900734\n",
      "[18]\ttraining's auc: 0.924152\tvalid_1's auc: 0.902799\n",
      "[19]\ttraining's auc: 0.925691\tvalid_1's auc: 0.903097\n",
      "[20]\ttraining's auc: 0.92571\tvalid_1's auc: 0.902815\n",
      "[21]\ttraining's auc: 0.926789\tvalid_1's auc: 0.905636\n",
      "[22]\ttraining's auc: 0.927897\tvalid_1's auc: 0.90668\n",
      "[23]\ttraining's auc: 0.928006\tvalid_1's auc: 0.907376\n",
      "[24]\ttraining's auc: 0.928144\tvalid_1's auc: 0.906174\n",
      "[25]\ttraining's auc: 0.927916\tvalid_1's auc: 0.90574\n",
      "[26]\ttraining's auc: 0.928022\tvalid_1's auc: 0.902225\n",
      "[27]\ttraining's auc: 0.928223\tvalid_1's auc: 0.903811\n",
      "[28]\ttraining's auc: 0.929519\tvalid_1's auc: 0.903007\n",
      "[29]\ttraining's auc: 0.929301\tvalid_1's auc: 0.903313\n",
      "[30]\ttraining's auc: 0.929908\tvalid_1's auc: 0.903023\n",
      "[31]\ttraining's auc: 0.93071\tvalid_1's auc: 0.904006\n",
      "[32]\ttraining's auc: 0.93085\tvalid_1's auc: 0.903394\n",
      "[33]\ttraining's auc: 0.930776\tvalid_1's auc: 0.901074\n",
      "[34]\ttraining's auc: 0.931923\tvalid_1's auc: 0.902215\n",
      "[35]\ttraining's auc: 0.932511\tvalid_1's auc: 0.903035\n",
      "[36]\ttraining's auc: 0.932407\tvalid_1's auc: 0.902959\n",
      "[37]\ttraining's auc: 0.932543\tvalid_1's auc: 0.900944\n",
      "[38]\ttraining's auc: 0.932671\tvalid_1's auc: 0.899567\n",
      "[39]\ttraining's auc: 0.932718\tvalid_1's auc: 0.899562\n",
      "[40]\ttraining's auc: 0.931598\tvalid_1's auc: 0.898398\n",
      "[41]\ttraining's auc: 0.930368\tvalid_1's auc: 0.898772\n",
      "[42]\ttraining's auc: 0.931273\tvalid_1's auc: 0.899005\n",
      "[43]\ttraining's auc: 0.931932\tvalid_1's auc: 0.898883\n",
      "[44]\ttraining's auc: 0.932554\tvalid_1's auc: 0.900337\n",
      "[45]\ttraining's auc: 0.932549\tvalid_1's auc: 0.899461\n",
      "[46]\ttraining's auc: 0.932436\tvalid_1's auc: 0.901872\n",
      "[47]\ttraining's auc: 0.932602\tvalid_1's auc: 0.900426\n",
      "[48]\ttraining's auc: 0.932613\tvalid_1's auc: 0.897735\n",
      "[49]\ttraining's auc: 0.932506\tvalid_1's auc: 0.896874\n",
      "[50]\ttraining's auc: 0.933155\tvalid_1's auc: 0.89603\n",
      "[51]\ttraining's auc: 0.933656\tvalid_1's auc: 0.897269\n",
      "[52]\ttraining's auc: 0.93333\tvalid_1's auc: 0.895964\n",
      "[53]\ttraining's auc: 0.930601\tvalid_1's auc: 0.893905\n",
      "[54]\ttraining's auc: 0.930987\tvalid_1's auc: 0.894136\n",
      "[55]\ttraining's auc: 0.932536\tvalid_1's auc: 0.893918\n",
      "[56]\ttraining's auc: 0.932816\tvalid_1's auc: 0.892343\n",
      "[57]\ttraining's auc: 0.933048\tvalid_1's auc: 0.893232\n",
      "[58]\ttraining's auc: 0.93357\tvalid_1's auc: 0.894494\n",
      "[59]\ttraining's auc: 0.93382\tvalid_1's auc: 0.894274\n",
      "[60]\ttraining's auc: 0.933864\tvalid_1's auc: 0.894396\n",
      "[61]\ttraining's auc: 0.933544\tvalid_1's auc: 0.893145\n",
      "[62]\ttraining's auc: 0.933991\tvalid_1's auc: 0.89115\n",
      "[63]\ttraining's auc: 0.934445\tvalid_1's auc: 0.891084\n",
      "[64]\ttraining's auc: 0.934125\tvalid_1's auc: 0.891059\n",
      "[65]\ttraining's auc: 0.934381\tvalid_1's auc: 0.889868\n",
      "[66]\ttraining's auc: 0.923067\tvalid_1's auc: 0.87643\n",
      "[67]\ttraining's auc: 0.928823\tvalid_1's auc: 0.8846\n",
      "[68]\ttraining's auc: 0.928518\tvalid_1's auc: 0.883466\n",
      "[69]\ttraining's auc: 0.928869\tvalid_1's auc: 0.884459\n",
      "[70]\ttraining's auc: 0.92972\tvalid_1's auc: 0.886267\n",
      "[71]\ttraining's auc: 0.931197\tvalid_1's auc: 0.890452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72]\ttraining's auc: 0.931732\tvalid_1's auc: 0.892086\n",
      "[73]\ttraining's auc: 0.931361\tvalid_1's auc: 0.889621\n",
      "[74]\ttraining's auc: 0.931871\tvalid_1's auc: 0.889631\n",
      "[75]\ttraining's auc: 0.931106\tvalid_1's auc: 0.887588\n",
      "[76]\ttraining's auc: 0.922894\tvalid_1's auc: 0.878922\n",
      "[77]\ttraining's auc: 0.923088\tvalid_1's auc: 0.87957\n",
      "[78]\ttraining's auc: 0.916694\tvalid_1's auc: 0.869632\n",
      "[79]\ttraining's auc: 0.922921\tvalid_1's auc: 0.876172\n",
      "[80]\ttraining's auc: 0.925978\tvalid_1's auc: 0.877771\n",
      "[81]\ttraining's auc: 0.927736\tvalid_1's auc: 0.879031\n",
      "[82]\ttraining's auc: 0.92686\tvalid_1's auc: 0.87696\n",
      "[83]\ttraining's auc: 0.926538\tvalid_1's auc: 0.875199\n",
      "[84]\ttraining's auc: 0.92793\tvalid_1's auc: 0.876447\n",
      "[85]\ttraining's auc: 0.92572\tvalid_1's auc: 0.876233\n",
      "[86]\ttraining's auc: 0.908335\tvalid_1's auc: 0.854727\n",
      "[87]\ttraining's auc: 0.914543\tvalid_1's auc: 0.862545\n",
      "[88]\ttraining's auc: 0.914749\tvalid_1's auc: 0.865396\n",
      "[89]\ttraining's auc: 0.919905\tvalid_1's auc: 0.871606\n",
      "[90]\ttraining's auc: 0.922399\tvalid_1's auc: 0.872679\n",
      "[91]\ttraining's auc: 0.924337\tvalid_1's auc: 0.872508\n",
      "[92]\ttraining's auc: 0.925064\tvalid_1's auc: 0.874894\n",
      "[93]\ttraining's auc: 0.920227\tvalid_1's auc: 0.876323\n",
      "[94]\ttraining's auc: 0.914057\tvalid_1's auc: 0.86455\n",
      "[95]\ttraining's auc: 0.925048\tvalid_1's auc: 0.876946\n",
      "[96]\ttraining's auc: 0.920668\tvalid_1's auc: 0.871235\n",
      "[97]\ttraining's auc: 0.920955\tvalid_1's auc: 0.871754\n",
      "[98]\ttraining's auc: 0.920377\tvalid_1's auc: 0.871769\n",
      "[99]\ttraining's auc: 0.921305\tvalid_1's auc: 0.872312\n",
      "[100]\ttraining's auc: 0.92312\tvalid_1's auc: 0.873349\n",
      "[101]\ttraining's auc: 0.923195\tvalid_1's auc: 0.872806\n",
      "[102]\ttraining's auc: 0.92307\tvalid_1's auc: 0.873299\n",
      "[103]\ttraining's auc: 0.922714\tvalid_1's auc: 0.873903\n",
      "[104]\ttraining's auc: 0.918438\tvalid_1's auc: 0.870221\n",
      "[105]\ttraining's auc: 0.915129\tvalid_1's auc: 0.868514\n",
      "[106]\ttraining's auc: 0.91565\tvalid_1's auc: 0.867627\n",
      "[107]\ttraining's auc: 0.916845\tvalid_1's auc: 0.868376\n",
      "[108]\ttraining's auc: 0.917155\tvalid_1's auc: 0.869352\n",
      "[109]\ttraining's auc: 0.920159\tvalid_1's auc: 0.873939\n",
      "[110]\ttraining's auc: 0.919717\tvalid_1's auc: 0.87369\n",
      "[111]\ttraining's auc: 0.920325\tvalid_1's auc: 0.872912\n",
      "[112]\ttraining's auc: 0.904104\tvalid_1's auc: 0.859414\n",
      "[113]\ttraining's auc: 0.905952\tvalid_1's auc: 0.861231\n",
      "[114]\ttraining's auc: 0.905263\tvalid_1's auc: 0.859464\n",
      "[115]\ttraining's auc: 0.907608\tvalid_1's auc: 0.863701\n",
      "[116]\ttraining's auc: 0.9065\tvalid_1's auc: 0.863289\n",
      "[117]\ttraining's auc: 0.902871\tvalid_1's auc: 0.852689\n",
      "[118]\ttraining's auc: 0.902328\tvalid_1's auc: 0.85283\n",
      "[119]\ttraining's auc: 0.891019\tvalid_1's auc: 0.836231\n",
      "[120]\ttraining's auc: 0.892598\tvalid_1's auc: 0.835917\n",
      "[121]\ttraining's auc: 0.89211\tvalid_1's auc: 0.842786\n",
      "[122]\ttraining's auc: 0.884588\tvalid_1's auc: 0.836528\n",
      "[123]\ttraining's auc: 0.884485\tvalid_1's auc: 0.836809\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.928006\tvalid_1's auc: 0.907376\n",
      "[1]\ttraining's auc: 0.874042\tvalid_1's auc: 0.86066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.885528\tvalid_1's auc: 0.880573\n",
      "[3]\ttraining's auc: 0.908964\tvalid_1's auc: 0.90181\n",
      "[4]\ttraining's auc: 0.913908\tvalid_1's auc: 0.909009\n",
      "[5]\ttraining's auc: 0.918592\tvalid_1's auc: 0.910747\n",
      "[6]\ttraining's auc: 0.92196\tvalid_1's auc: 0.914373\n",
      "[7]\ttraining's auc: 0.922335\tvalid_1's auc: 0.915593\n",
      "[8]\ttraining's auc: 0.92444\tvalid_1's auc: 0.916542\n",
      "[9]\ttraining's auc: 0.925749\tvalid_1's auc: 0.91526\n",
      "[10]\ttraining's auc: 0.927682\tvalid_1's auc: 0.918085\n",
      "[11]\ttraining's auc: 0.929413\tvalid_1's auc: 0.919701\n",
      "[12]\ttraining's auc: 0.929582\tvalid_1's auc: 0.921026\n",
      "[13]\ttraining's auc: 0.929324\tvalid_1's auc: 0.918426\n",
      "[14]\ttraining's auc: 0.930166\tvalid_1's auc: 0.917689\n",
      "[15]\ttraining's auc: 0.930523\tvalid_1's auc: 0.918579\n",
      "[16]\ttraining's auc: 0.931338\tvalid_1's auc: 0.919429\n",
      "[17]\ttraining's auc: 0.931346\tvalid_1's auc: 0.917296\n",
      "[18]\ttraining's auc: 0.931842\tvalid_1's auc: 0.916016\n",
      "[19]\ttraining's auc: 0.932111\tvalid_1's auc: 0.917226\n",
      "[20]\ttraining's auc: 0.932768\tvalid_1's auc: 0.916375\n",
      "[21]\ttraining's auc: 0.93346\tvalid_1's auc: 0.916142\n",
      "[22]\ttraining's auc: 0.933532\tvalid_1's auc: 0.914541\n",
      "[23]\ttraining's auc: 0.933715\tvalid_1's auc: 0.912007\n",
      "[24]\ttraining's auc: 0.934907\tvalid_1's auc: 0.913401\n",
      "[25]\ttraining's auc: 0.93524\tvalid_1's auc: 0.912553\n",
      "[26]\ttraining's auc: 0.935319\tvalid_1's auc: 0.912701\n",
      "[27]\ttraining's auc: 0.934635\tvalid_1's auc: 0.912401\n",
      "[28]\ttraining's auc: 0.93364\tvalid_1's auc: 0.909318\n",
      "[29]\ttraining's auc: 0.934157\tvalid_1's auc: 0.909088\n",
      "[30]\ttraining's auc: 0.933774\tvalid_1's auc: 0.907202\n",
      "[31]\ttraining's auc: 0.933864\tvalid_1's auc: 0.907334\n",
      "[32]\ttraining's auc: 0.933661\tvalid_1's auc: 0.906536\n",
      "[33]\ttraining's auc: 0.933778\tvalid_1's auc: 0.906964\n",
      "[34]\ttraining's auc: 0.933626\tvalid_1's auc: 0.906467\n",
      "[35]\ttraining's auc: 0.933843\tvalid_1's auc: 0.906215\n",
      "[36]\ttraining's auc: 0.933528\tvalid_1's auc: 0.906832\n",
      "[37]\ttraining's auc: 0.933939\tvalid_1's auc: 0.905721\n",
      "[38]\ttraining's auc: 0.933709\tvalid_1's auc: 0.904138\n",
      "[39]\ttraining's auc: 0.93409\tvalid_1's auc: 0.902925\n",
      "[40]\ttraining's auc: 0.934602\tvalid_1's auc: 0.903726\n",
      "[41]\ttraining's auc: 0.934249\tvalid_1's auc: 0.902346\n",
      "[42]\ttraining's auc: 0.934763\tvalid_1's auc: 0.901909\n",
      "[43]\ttraining's auc: 0.934928\tvalid_1's auc: 0.903035\n",
      "[44]\ttraining's auc: 0.935213\tvalid_1's auc: 0.902053\n",
      "[45]\ttraining's auc: 0.933618\tvalid_1's auc: 0.898617\n",
      "[46]\ttraining's auc: 0.933906\tvalid_1's auc: 0.897739\n",
      "[47]\ttraining's auc: 0.934213\tvalid_1's auc: 0.896206\n",
      "[48]\ttraining's auc: 0.935068\tvalid_1's auc: 0.896449\n",
      "[49]\ttraining's auc: 0.935526\tvalid_1's auc: 0.896119\n",
      "[50]\ttraining's auc: 0.935641\tvalid_1's auc: 0.897613\n",
      "[51]\ttraining's auc: 0.93653\tvalid_1's auc: 0.899747\n",
      "[52]\ttraining's auc: 0.936783\tvalid_1's auc: 0.901312\n",
      "[53]\ttraining's auc: 0.935504\tvalid_1's auc: 0.900197\n",
      "[54]\ttraining's auc: 0.936366\tvalid_1's auc: 0.898276\n",
      "[55]\ttraining's auc: 0.937295\tvalid_1's auc: 0.899838\n",
      "[56]\ttraining's auc: 0.937829\tvalid_1's auc: 0.901352\n",
      "[57]\ttraining's auc: 0.937877\tvalid_1's auc: 0.898237\n",
      "[58]\ttraining's auc: 0.938433\tvalid_1's auc: 0.897648\n",
      "[59]\ttraining's auc: 0.938471\tvalid_1's auc: 0.899337\n",
      "[60]\ttraining's auc: 0.931947\tvalid_1's auc: 0.894785\n",
      "[61]\ttraining's auc: 0.933724\tvalid_1's auc: 0.897088\n",
      "[62]\ttraining's auc: 0.932326\tvalid_1's auc: 0.893339\n",
      "[63]\ttraining's auc: 0.93269\tvalid_1's auc: 0.892764\n",
      "[64]\ttraining's auc: 0.934514\tvalid_1's auc: 0.896519\n",
      "[65]\ttraining's auc: 0.925096\tvalid_1's auc: 0.891439\n",
      "[66]\ttraining's auc: 0.929399\tvalid_1's auc: 0.89455\n",
      "[67]\ttraining's auc: 0.927855\tvalid_1's auc: 0.894217\n",
      "[68]\ttraining's auc: 0.927236\tvalid_1's auc: 0.893103\n",
      "[69]\ttraining's auc: 0.932099\tvalid_1's auc: 0.898001\n",
      "[70]\ttraining's auc: 0.931339\tvalid_1's auc: 0.89602\n",
      "[71]\ttraining's auc: 0.931277\tvalid_1's auc: 0.896848\n",
      "[72]\ttraining's auc: 0.923451\tvalid_1's auc: 0.885703\n",
      "[73]\ttraining's auc: 0.928246\tvalid_1's auc: 0.892841\n",
      "[74]\ttraining's auc: 0.92816\tvalid_1's auc: 0.893643\n",
      "[75]\ttraining's auc: 0.92556\tvalid_1's auc: 0.88996\n",
      "[76]\ttraining's auc: 0.925141\tvalid_1's auc: 0.887615\n",
      "[77]\ttraining's auc: 0.924779\tvalid_1's auc: 0.889306\n",
      "[78]\ttraining's auc: 0.923562\tvalid_1's auc: 0.885959\n",
      "[79]\ttraining's auc: 0.908789\tvalid_1's auc: 0.868787\n",
      "[80]\ttraining's auc: 0.923868\tvalid_1's auc: 0.88382\n",
      "[81]\ttraining's auc: 0.924317\tvalid_1's auc: 0.879808\n",
      "[82]\ttraining's auc: 0.923544\tvalid_1's auc: 0.879005\n",
      "[83]\ttraining's auc: 0.917666\tvalid_1's auc: 0.872668\n",
      "[84]\ttraining's auc: 0.919687\tvalid_1's auc: 0.876568\n",
      "[85]\ttraining's auc: 0.919244\tvalid_1's auc: 0.875973\n",
      "[86]\ttraining's auc: 0.919297\tvalid_1's auc: 0.877886\n",
      "[87]\ttraining's auc: 0.902569\tvalid_1's auc: 0.867552\n",
      "[88]\ttraining's auc: 0.917931\tvalid_1's auc: 0.884047\n",
      "[89]\ttraining's auc: 0.915352\tvalid_1's auc: 0.881481\n",
      "[90]\ttraining's auc: 0.893483\tvalid_1's auc: 0.863307\n",
      "[91]\ttraining's auc: 0.905747\tvalid_1's auc: 0.872584\n",
      "[92]\ttraining's auc: 0.909872\tvalid_1's auc: 0.875199\n",
      "[93]\ttraining's auc: 0.904941\tvalid_1's auc: 0.872431\n",
      "[94]\ttraining's auc: 0.906172\tvalid_1's auc: 0.880578\n",
      "[95]\ttraining's auc: 0.887372\tvalid_1's auc: 0.86122\n",
      "[96]\ttraining's auc: 0.88484\tvalid_1's auc: 0.857727\n",
      "[97]\ttraining's auc: 0.8927\tvalid_1's auc: 0.856942\n",
      "[98]\ttraining's auc: 0.895162\tvalid_1's auc: 0.859314\n",
      "[99]\ttraining's auc: 0.882768\tvalid_1's auc: 0.844467\n",
      "[100]\ttraining's auc: 0.894633\tvalid_1's auc: 0.856919\n",
      "[101]\ttraining's auc: 0.892609\tvalid_1's auc: 0.857466\n",
      "[102]\ttraining's auc: 0.894433\tvalid_1's auc: 0.858808\n",
      "[103]\ttraining's auc: 0.88507\tvalid_1's auc: 0.849542\n",
      "[104]\ttraining's auc: 0.88101\tvalid_1's auc: 0.846867\n",
      "[105]\ttraining's auc: 0.88481\tvalid_1's auc: 0.849467\n",
      "[106]\ttraining's auc: 0.881429\tvalid_1's auc: 0.844068\n",
      "[107]\ttraining's auc: 0.885334\tvalid_1's auc: 0.855548\n",
      "[108]\ttraining's auc: 0.886699\tvalid_1's auc: 0.858167\n",
      "[109]\ttraining's auc: 0.884853\tvalid_1's auc: 0.85696\n",
      "[110]\ttraining's auc: 0.885276\tvalid_1's auc: 0.856974\n",
      "[111]\ttraining's auc: 0.882894\tvalid_1's auc: 0.86164\n",
      "[112]\ttraining's auc: 0.88236\tvalid_1's auc: 0.85481\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.929582\tvalid_1's auc: 0.921026\n",
      "[1]\ttraining's auc: 0.871574\tvalid_1's auc: 0.850538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.8825\tvalid_1's auc: 0.851257\n",
      "[3]\ttraining's auc: 0.905615\tvalid_1's auc: 0.880183\n",
      "[4]\ttraining's auc: 0.910929\tvalid_1's auc: 0.887578\n",
      "[5]\ttraining's auc: 0.913674\tvalid_1's auc: 0.888758\n",
      "[6]\ttraining's auc: 0.916041\tvalid_1's auc: 0.892826\n",
      "[7]\ttraining's auc: 0.917219\tvalid_1's auc: 0.890521\n",
      "[8]\ttraining's auc: 0.919087\tvalid_1's auc: 0.892899\n",
      "[9]\ttraining's auc: 0.920959\tvalid_1's auc: 0.892632\n",
      "[10]\ttraining's auc: 0.922622\tvalid_1's auc: 0.89591\n",
      "[11]\ttraining's auc: 0.924985\tvalid_1's auc: 0.89667\n",
      "[12]\ttraining's auc: 0.925703\tvalid_1's auc: 0.894598\n",
      "[13]\ttraining's auc: 0.92739\tvalid_1's auc: 0.897517\n",
      "[14]\ttraining's auc: 0.928135\tvalid_1's auc: 0.896267\n",
      "[15]\ttraining's auc: 0.928177\tvalid_1's auc: 0.895183\n",
      "[16]\ttraining's auc: 0.928979\tvalid_1's auc: 0.894726\n",
      "[17]\ttraining's auc: 0.929483\tvalid_1's auc: 0.895991\n",
      "[18]\ttraining's auc: 0.929432\tvalid_1's auc: 0.895671\n",
      "[19]\ttraining's auc: 0.930701\tvalid_1's auc: 0.896454\n",
      "[20]\ttraining's auc: 0.930819\tvalid_1's auc: 0.895225\n",
      "[21]\ttraining's auc: 0.932809\tvalid_1's auc: 0.897571\n",
      "[22]\ttraining's auc: 0.933168\tvalid_1's auc: 0.89903\n",
      "[23]\ttraining's auc: 0.933392\tvalid_1's auc: 0.897645\n",
      "[24]\ttraining's auc: 0.933089\tvalid_1's auc: 0.895958\n",
      "[25]\ttraining's auc: 0.933301\tvalid_1's auc: 0.8963\n",
      "[26]\ttraining's auc: 0.934236\tvalid_1's auc: 0.896126\n",
      "[27]\ttraining's auc: 0.934465\tvalid_1's auc: 0.893479\n",
      "[28]\ttraining's auc: 0.935208\tvalid_1's auc: 0.894787\n",
      "[29]\ttraining's auc: 0.935487\tvalid_1's auc: 0.894654\n",
      "[30]\ttraining's auc: 0.935747\tvalid_1's auc: 0.894727\n",
      "[31]\ttraining's auc: 0.935891\tvalid_1's auc: 0.893007\n",
      "[32]\ttraining's auc: 0.936188\tvalid_1's auc: 0.892003\n",
      "[33]\ttraining's auc: 0.935887\tvalid_1's auc: 0.890961\n",
      "[34]\ttraining's auc: 0.935779\tvalid_1's auc: 0.891604\n",
      "[35]\ttraining's auc: 0.935979\tvalid_1's auc: 0.890868\n",
      "[36]\ttraining's auc: 0.936322\tvalid_1's auc: 0.891889\n",
      "[37]\ttraining's auc: 0.936535\tvalid_1's auc: 0.890584\n",
      "[38]\ttraining's auc: 0.936406\tvalid_1's auc: 0.890418\n",
      "[39]\ttraining's auc: 0.936195\tvalid_1's auc: 0.889978\n",
      "[40]\ttraining's auc: 0.934258\tvalid_1's auc: 0.887699\n",
      "[41]\ttraining's auc: 0.935117\tvalid_1's auc: 0.889249\n",
      "[42]\ttraining's auc: 0.934743\tvalid_1's auc: 0.889654\n",
      "[43]\ttraining's auc: 0.934788\tvalid_1's auc: 0.88971\n",
      "[44]\ttraining's auc: 0.935355\tvalid_1's auc: 0.888343\n",
      "[45]\ttraining's auc: 0.935485\tvalid_1's auc: 0.888092\n",
      "[46]\ttraining's auc: 0.935499\tvalid_1's auc: 0.885581\n",
      "[47]\ttraining's auc: 0.934039\tvalid_1's auc: 0.884587\n",
      "[48]\ttraining's auc: 0.933945\tvalid_1's auc: 0.886816\n",
      "[49]\ttraining's auc: 0.93368\tvalid_1's auc: 0.886192\n",
      "[50]\ttraining's auc: 0.933833\tvalid_1's auc: 0.887103\n",
      "[51]\ttraining's auc: 0.933669\tvalid_1's auc: 0.887523\n",
      "[52]\ttraining's auc: 0.934393\tvalid_1's auc: 0.887922\n",
      "[53]\ttraining's auc: 0.933819\tvalid_1's auc: 0.887833\n",
      "[54]\ttraining's auc: 0.933754\tvalid_1's auc: 0.886928\n",
      "[55]\ttraining's auc: 0.934598\tvalid_1's auc: 0.888635\n",
      "[56]\ttraining's auc: 0.935717\tvalid_1's auc: 0.887246\n",
      "[57]\ttraining's auc: 0.935994\tvalid_1's auc: 0.885882\n",
      "[58]\ttraining's auc: 0.936641\tvalid_1's auc: 0.886202\n",
      "[59]\ttraining's auc: 0.936151\tvalid_1's auc: 0.883613\n",
      "[60]\ttraining's auc: 0.934841\tvalid_1's auc: 0.882517\n",
      "[61]\ttraining's auc: 0.935493\tvalid_1's auc: 0.882974\n",
      "[62]\ttraining's auc: 0.936509\tvalid_1's auc: 0.885051\n",
      "[63]\ttraining's auc: 0.936808\tvalid_1's auc: 0.887624\n",
      "[64]\ttraining's auc: 0.937539\tvalid_1's auc: 0.888178\n",
      "[65]\ttraining's auc: 0.937963\tvalid_1's auc: 0.888619\n",
      "[66]\ttraining's auc: 0.937484\tvalid_1's auc: 0.887084\n",
      "[67]\ttraining's auc: 0.938807\tvalid_1's auc: 0.886189\n",
      "[68]\ttraining's auc: 0.938744\tvalid_1's auc: 0.886477\n",
      "[69]\ttraining's auc: 0.939208\tvalid_1's auc: 0.887134\n",
      "[70]\ttraining's auc: 0.939286\tvalid_1's auc: 0.886324\n",
      "[71]\ttraining's auc: 0.939049\tvalid_1's auc: 0.885539\n",
      "[72]\ttraining's auc: 0.938528\tvalid_1's auc: 0.884253\n",
      "[73]\ttraining's auc: 0.939429\tvalid_1's auc: 0.885114\n",
      "[74]\ttraining's auc: 0.939002\tvalid_1's auc: 0.882563\n",
      "[75]\ttraining's auc: 0.939335\tvalid_1's auc: 0.882811\n",
      "[76]\ttraining's auc: 0.939713\tvalid_1's auc: 0.881845\n",
      "[77]\ttraining's auc: 0.938525\tvalid_1's auc: 0.881656\n",
      "[78]\ttraining's auc: 0.938171\tvalid_1's auc: 0.879225\n",
      "[79]\ttraining's auc: 0.938156\tvalid_1's auc: 0.878033\n",
      "[80]\ttraining's auc: 0.937831\tvalid_1's auc: 0.878794\n",
      "[81]\ttraining's auc: 0.938401\tvalid_1's auc: 0.87908\n",
      "[82]\ttraining's auc: 0.939213\tvalid_1's auc: 0.88\n",
      "[83]\ttraining's auc: 0.938821\tvalid_1's auc: 0.877639\n",
      "[84]\ttraining's auc: 0.937795\tvalid_1's auc: 0.876621\n",
      "[85]\ttraining's auc: 0.931064\tvalid_1's auc: 0.867142\n",
      "[86]\ttraining's auc: 0.93113\tvalid_1's auc: 0.866757\n",
      "[87]\ttraining's auc: 0.932246\tvalid_1's auc: 0.868689\n",
      "[88]\ttraining's auc: 0.934465\tvalid_1's auc: 0.872332\n",
      "[89]\ttraining's auc: 0.933244\tvalid_1's auc: 0.871569\n",
      "[90]\ttraining's auc: 0.933362\tvalid_1's auc: 0.873219\n",
      "[91]\ttraining's auc: 0.932724\tvalid_1's auc: 0.872361\n",
      "[92]\ttraining's auc: 0.931491\tvalid_1's auc: 0.870778\n",
      "[93]\ttraining's auc: 0.925284\tvalid_1's auc: 0.862109\n",
      "[94]\ttraining's auc: 0.927822\tvalid_1's auc: 0.863717\n",
      "[95]\ttraining's auc: 0.915493\tvalid_1's auc: 0.853855\n",
      "[96]\ttraining's auc: 0.906304\tvalid_1's auc: 0.839235\n",
      "[97]\ttraining's auc: 0.92385\tvalid_1's auc: 0.860001\n",
      "[98]\ttraining's auc: 0.928373\tvalid_1's auc: 0.867829\n",
      "[99]\ttraining's auc: 0.917947\tvalid_1's auc: 0.858815\n",
      "[100]\ttraining's auc: 0.9194\tvalid_1's auc: 0.862432\n",
      "[101]\ttraining's auc: 0.919697\tvalid_1's auc: 0.86325\n",
      "[102]\ttraining's auc: 0.918815\tvalid_1's auc: 0.86049\n",
      "[103]\ttraining's auc: 0.916186\tvalid_1's auc: 0.862207\n",
      "[104]\ttraining's auc: 0.915567\tvalid_1's auc: 0.867355\n",
      "[105]\ttraining's auc: 0.915265\tvalid_1's auc: 0.867421\n",
      "[106]\ttraining's auc: 0.900699\tvalid_1's auc: 0.849814\n",
      "[107]\ttraining's auc: 0.914372\tvalid_1's auc: 0.861221\n",
      "[108]\ttraining's auc: 0.917027\tvalid_1's auc: 0.863832\n",
      "[109]\ttraining's auc: 0.914482\tvalid_1's auc: 0.861067\n",
      "[110]\ttraining's auc: 0.915204\tvalid_1's auc: 0.8603\n",
      "[111]\ttraining's auc: 0.913694\tvalid_1's auc: 0.85879\n",
      "[112]\ttraining's auc: 0.913901\tvalid_1's auc: 0.859568\n",
      "[113]\ttraining's auc: 0.901187\tvalid_1's auc: 0.843165\n",
      "[114]\ttraining's auc: 0.909972\tvalid_1's auc: 0.861571\n",
      "[115]\ttraining's auc: 0.910428\tvalid_1's auc: 0.860924\n",
      "[116]\ttraining's auc: 0.910089\tvalid_1's auc: 0.859314\n",
      "[117]\ttraining's auc: 0.910637\tvalid_1's auc: 0.860992\n",
      "[118]\ttraining's auc: 0.903827\tvalid_1's auc: 0.851538\n",
      "[119]\ttraining's auc: 0.903387\tvalid_1's auc: 0.853025\n",
      "[120]\ttraining's auc: 0.903026\tvalid_1's auc: 0.852938\n",
      "[121]\ttraining's auc: 0.908322\tvalid_1's auc: 0.860126\n",
      "[122]\ttraining's auc: 0.908182\tvalid_1's auc: 0.857762\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.933168\tvalid_1's auc: 0.89903\n"
     ]
    }
   ],
   "source": [
    "n_splits=10\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "train_x = data[data['y']!=-1][feats]\n",
    "train_y = data[data['y']!=-1]['y']\n",
    "res = data[data['y']==-1][['ID']]\n",
    "\n",
    "test_x = data[data['y']==-1][feats]\n",
    "res['pred']=0\n",
    "for train_idx, val_idx, in kfold.split(train_x):\n",
    "    model.random_state = model.random_state + 1\n",
    "    train_x1 = train_x.loc[train_idx]\n",
    "    train_y1 = train_y.loc[train_idx]\n",
    "    test_x1 = train_x.loc[val_idx]\n",
    "    test_y1 = train_y.loc[val_idx]\n",
    "    model.fit(train_x1, train_y1, eval_set=[(train_x1, train_y1),(test_x1, test_y1)],\n",
    "              eval_metric='auc',early_stopping_rounds=100)\n",
    "    res['pred'] += model.predict_proba(test_x)[:,1]\n",
    "res['pred'] = res['pred']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
